{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "sns.set_palette('colorblind')\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>why are yawns contagious? when people yawn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>what is trans fat? how to reduce that? i heard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>roth ira vs 401k? what is the difference betwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>how many planes fedex has? i heard that it is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>what is the best photo slideshow creation appl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                               Text\n",
       "0         5         why are yawns contagious? when people yawn\n",
       "1         6  what is trans fat? how to reduce that? i heard...\n",
       "2         1  roth ira vs 401k? what is the difference betwe...\n",
       "3         1  how many planes fedex has? i heard that it is ...\n",
       "4         2  what is the best photo slideshow creation appl..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('newtrain.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tokenize text\n",
    "pattern = r'''(?x)    # set flag to allow verbose regexps\n",
    "     ([A-Z]\\.)+        # abbreviations, e.g. U.S.A.\n",
    "   | \\w+([-']\\w+)*        # words with optional internal hyphens\n",
    "   | \\$?\\d+(\\.\\d+)?%?  # currency and percentages, e.g. $12.40, 82%\n",
    "   | \\.\\.\\.            # ellipsis\n",
    "   | [.,;\"?():-_`]+  # these are separate tokens\n",
    " '''\n",
    "\n",
    "tokenize = lambda text: nltk.regexp_tokenize(text, pattern)\n",
    "df['Text'] = df['Text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>[why, are, yawns, contagious, ?, when, people,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>[what, is, trans, fat, ?, how, to, reduce, tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[roth, ira, vs, 401k, ?, what, is, the, differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[how, many, planes, fedex, has, ?, i, heard, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>[what, is, the, best, photo, slideshow, creati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                               Text\n",
       "0         5  [why, are, yawns, contagious, ?, when, people,...\n",
       "1         6  [what, is, trans, fat, ?, how, to, reduce, tha...\n",
       "2         1  [roth, ira, vs, 401k, ?, what, is, the, differ...\n",
       "3         1  [how, many, planes, fedex, has, ?, i, heard, t...\n",
       "4         2  [what, is, the, best, photo, slideshow, creati..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove punctuation, stopwords\n",
    "#rem_chars = [p for p in string.punctuation] + list(ENGLISH_STOP_WORDS)\n",
    "rem_chars = [p for p in string.punctuation]\n",
    "rem = lambda a: ' '.join([i for i in a if i not in rem_chars])\n",
    "#rem = lambda a: [i for i in a if i not in rem_chars]\n",
    "df['Text'] = df['Text'].apply(rem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>why are yawns contagious when people yawn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>what is trans fat how to reduce that i heard t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>roth ira vs 401k what is the difference betwee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>how many planes fedex has i heard that it is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>what is the best photo slideshow creation appl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                               Text\n",
       "0         5          why are yawns contagious when people yawn\n",
       "1         6  what is trans fat how to reduce that i heard t...\n",
       "2         1  roth ira vs 401k what is the difference betwee...\n",
       "3         1  how many planes fedex has i heard that it is t...\n",
       "4         2  what is the best photo slideshow creation appl..."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove html and punctuation\n",
    "#rem_chars = ['http', 'www', 'com', 'html'] + [p for p in string.punctuation]\n",
    "#rem = lambda a: [i for i in a if i not in rem_chars]\n",
    "#df['Text'] = df['Text'].apply(rem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is lin qingxia aka brigitte lin the most beautiful woman in chinese cinema this is according to stephen chow http www hkentreview com 2005 features kfh kfhprem html ). is it true who is the best-looking male star did they make any movies together'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Text.iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'a',\n",
       "           'about',\n",
       "           'above',\n",
       "           'across',\n",
       "           'after',\n",
       "           'afterwards',\n",
       "           'again',\n",
       "           'against',\n",
       "           'all',\n",
       "           'almost',\n",
       "           'alone',\n",
       "           'along',\n",
       "           'already',\n",
       "           'also',\n",
       "           'although',\n",
       "           'always',\n",
       "           'am',\n",
       "           'among',\n",
       "           'amongst',\n",
       "           'amoungst',\n",
       "           'amount',\n",
       "           'an',\n",
       "           'and',\n",
       "           'another',\n",
       "           'any',\n",
       "           'anyhow',\n",
       "           'anyone',\n",
       "           'anything',\n",
       "           'anyway',\n",
       "           'anywhere',\n",
       "           'are',\n",
       "           'around',\n",
       "           'as',\n",
       "           'at',\n",
       "           'back',\n",
       "           'be',\n",
       "           'became',\n",
       "           'because',\n",
       "           'become',\n",
       "           'becomes',\n",
       "           'becoming',\n",
       "           'been',\n",
       "           'before',\n",
       "           'beforehand',\n",
       "           'behind',\n",
       "           'being',\n",
       "           'below',\n",
       "           'beside',\n",
       "           'besides',\n",
       "           'between',\n",
       "           'beyond',\n",
       "           'bill',\n",
       "           'both',\n",
       "           'bottom',\n",
       "           'but',\n",
       "           'by',\n",
       "           'call',\n",
       "           'can',\n",
       "           'cannot',\n",
       "           'cant',\n",
       "           'co',\n",
       "           'con',\n",
       "           'could',\n",
       "           'couldnt',\n",
       "           'cry',\n",
       "           'de',\n",
       "           'describe',\n",
       "           'detail',\n",
       "           'do',\n",
       "           'done',\n",
       "           'down',\n",
       "           'due',\n",
       "           'during',\n",
       "           'each',\n",
       "           'eg',\n",
       "           'eight',\n",
       "           'either',\n",
       "           'eleven',\n",
       "           'else',\n",
       "           'elsewhere',\n",
       "           'empty',\n",
       "           'enough',\n",
       "           'etc',\n",
       "           'even',\n",
       "           'ever',\n",
       "           'every',\n",
       "           'everyone',\n",
       "           'everything',\n",
       "           'everywhere',\n",
       "           'except',\n",
       "           'few',\n",
       "           'fifteen',\n",
       "           'fify',\n",
       "           'fill',\n",
       "           'find',\n",
       "           'fire',\n",
       "           'first',\n",
       "           'five',\n",
       "           'for',\n",
       "           'former',\n",
       "           'formerly',\n",
       "           'forty',\n",
       "           'found',\n",
       "           'four',\n",
       "           'from',\n",
       "           'front',\n",
       "           'full',\n",
       "           'further',\n",
       "           'get',\n",
       "           'give',\n",
       "           'go',\n",
       "           'had',\n",
       "           'has',\n",
       "           'hasnt',\n",
       "           'have',\n",
       "           'he',\n",
       "           'hence',\n",
       "           'her',\n",
       "           'here',\n",
       "           'hereafter',\n",
       "           'hereby',\n",
       "           'herein',\n",
       "           'hereupon',\n",
       "           'hers',\n",
       "           'herself',\n",
       "           'him',\n",
       "           'himself',\n",
       "           'his',\n",
       "           'how',\n",
       "           'however',\n",
       "           'hundred',\n",
       "           'i',\n",
       "           'ie',\n",
       "           'if',\n",
       "           'in',\n",
       "           'inc',\n",
       "           'indeed',\n",
       "           'interest',\n",
       "           'into',\n",
       "           'is',\n",
       "           'it',\n",
       "           'its',\n",
       "           'itself',\n",
       "           'keep',\n",
       "           'last',\n",
       "           'latter',\n",
       "           'latterly',\n",
       "           'least',\n",
       "           'less',\n",
       "           'ltd',\n",
       "           'made',\n",
       "           'many',\n",
       "           'may',\n",
       "           'me',\n",
       "           'meanwhile',\n",
       "           'might',\n",
       "           'mill',\n",
       "           'mine',\n",
       "           'more',\n",
       "           'moreover',\n",
       "           'most',\n",
       "           'mostly',\n",
       "           'move',\n",
       "           'much',\n",
       "           'must',\n",
       "           'my',\n",
       "           'myself',\n",
       "           'name',\n",
       "           'namely',\n",
       "           'neither',\n",
       "           'never',\n",
       "           'nevertheless',\n",
       "           'next',\n",
       "           'nine',\n",
       "           'no',\n",
       "           'nobody',\n",
       "           'none',\n",
       "           'noone',\n",
       "           'nor',\n",
       "           'not',\n",
       "           'nothing',\n",
       "           'now',\n",
       "           'nowhere',\n",
       "           'of',\n",
       "           'off',\n",
       "           'often',\n",
       "           'on',\n",
       "           'once',\n",
       "           'one',\n",
       "           'only',\n",
       "           'onto',\n",
       "           'or',\n",
       "           'other',\n",
       "           'others',\n",
       "           'otherwise',\n",
       "           'our',\n",
       "           'ours',\n",
       "           'ourselves',\n",
       "           'out',\n",
       "           'over',\n",
       "           'own',\n",
       "           'part',\n",
       "           'per',\n",
       "           'perhaps',\n",
       "           'please',\n",
       "           'put',\n",
       "           'rather',\n",
       "           're',\n",
       "           'same',\n",
       "           'see',\n",
       "           'seem',\n",
       "           'seemed',\n",
       "           'seeming',\n",
       "           'seems',\n",
       "           'serious',\n",
       "           'several',\n",
       "           'she',\n",
       "           'should',\n",
       "           'show',\n",
       "           'side',\n",
       "           'since',\n",
       "           'sincere',\n",
       "           'six',\n",
       "           'sixty',\n",
       "           'so',\n",
       "           'some',\n",
       "           'somehow',\n",
       "           'someone',\n",
       "           'something',\n",
       "           'sometime',\n",
       "           'sometimes',\n",
       "           'somewhere',\n",
       "           'still',\n",
       "           'such',\n",
       "           'system',\n",
       "           'take',\n",
       "           'ten',\n",
       "           'than',\n",
       "           'that',\n",
       "           'the',\n",
       "           'their',\n",
       "           'them',\n",
       "           'themselves',\n",
       "           'then',\n",
       "           'thence',\n",
       "           'there',\n",
       "           'thereafter',\n",
       "           'thereby',\n",
       "           'therefore',\n",
       "           'therein',\n",
       "           'thereupon',\n",
       "           'these',\n",
       "           'they',\n",
       "           'thick',\n",
       "           'thin',\n",
       "           'third',\n",
       "           'this',\n",
       "           'those',\n",
       "           'though',\n",
       "           'three',\n",
       "           'through',\n",
       "           'throughout',\n",
       "           'thru',\n",
       "           'thus',\n",
       "           'to',\n",
       "           'together',\n",
       "           'too',\n",
       "           'top',\n",
       "           'toward',\n",
       "           'towards',\n",
       "           'twelve',\n",
       "           'twenty',\n",
       "           'two',\n",
       "           'un',\n",
       "           'under',\n",
       "           'until',\n",
       "           'up',\n",
       "           'upon',\n",
       "           'us',\n",
       "           'very',\n",
       "           'via',\n",
       "           'was',\n",
       "           'we',\n",
       "           'well',\n",
       "           'were',\n",
       "           'what',\n",
       "           'whatever',\n",
       "           'when',\n",
       "           'whence',\n",
       "           'whenever',\n",
       "           'where',\n",
       "           'whereafter',\n",
       "           'whereas',\n",
       "           'whereby',\n",
       "           'wherein',\n",
       "           'whereupon',\n",
       "           'wherever',\n",
       "           'whether',\n",
       "           'which',\n",
       "           'while',\n",
       "           'whither',\n",
       "           'who',\n",
       "           'whoever',\n",
       "           'whole',\n",
       "           'whom',\n",
       "           'whose',\n",
       "           'why',\n",
       "           'will',\n",
       "           'with',\n",
       "           'within',\n",
       "           'without',\n",
       "           'would',\n",
       "           'yet',\n",
       "           'you',\n",
       "           'your',\n",
       "           'yours',\n",
       "           'yourself',\n",
       "           'yourselves'})"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear SVC\n",
      "\tmean score: 0.548888888888889\n",
      "\n",
      "Naive Bayes\n",
      "\t mean score: 0.5448148148148149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n#decision tree\\nmod = DecisionTreeClassifier(criterion = 'entropy')\\ncv = StratifiedShuffleSplit(targets, n_iter = 10, test_size = 0.1)\\n\\nscores = []\\nfor tr, tt in cv:\\n    mod.fit(counts[tr], targets[tr])\\n    scores.append(mod.score(counts[tt],targets[tt]))\\nprint('\\nDecision Tree\\n\\t mean score: {0}'.format(np.mean(scores)))\\n\""
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorize data\n",
    "#turns words into a list of vectors - vector length is the total number of words\n",
    "#Vector elements correspond to 1 word (1/0 if word is/not present in the current item)\n",
    "\n",
    "#targets\n",
    "vec_tar = LabelEncoder()\n",
    "targets = vec_tar.fit_transform(df['Category'])\n",
    "\n",
    "#counts\n",
    "vec = CountVectorizer(stop_words=ENGLISH_STOP_WORDS, max_features = 1000)\n",
    "counts = vec.fit_transform(df['Text']) \n",
    "\n",
    "\n",
    "#linear SVC\n",
    "mod = LinearSVC(C=.1)\n",
    "cv = StratifiedShuffleSplit(targets, n_iter=10, test_size=.1)\n",
    "\n",
    "scores = []\n",
    "for tr, tt in cv:\n",
    "    mod.fit(counts[tr], targets[tr])\n",
    "    scores.append(mod.score(counts[tt],targets[tt]))\n",
    "print('\\nLinear SVC\\n\\tmean score: {0}'.format(np.mean(scores)))\n",
    "\n",
    "\n",
    "#naive bayes\n",
    "mod = MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
    "cv = StratifiedShuffleSplit(targets, n_iter = 10, test_size = 0.1)\n",
    "\n",
    "scores = []\n",
    "for tr, tt in cv:\n",
    "    mod.fit(counts[tr], targets[tr])\n",
    "    scores.append(mod.score(counts[tt],targets[tt]))\n",
    "print('\\nNaive Bayes\\n\\t mean score: {0}'.format(np.mean(scores)))\n",
    "\n",
    "'''\n",
    "#decision tree\n",
    "mod = DecisionTreeClassifier(criterion = 'entropy')\n",
    "cv = StratifiedShuffleSplit(targets, n_iter = 10, test_size = 0.1)\n",
    "\n",
    "scores = []\n",
    "for tr, tt in cv:\n",
    "    mod.fit(counts[tr], targets[tr])\n",
    "    scores.append(mod.score(counts[tt],targets[tt]))\n",
    "print('\\nDecision Tree\\n\\t mean score: {0}'.format(np.mean(scores)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10000000000000001"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2698, 1000)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = vec.fit_transform(df['Text']) \n",
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2698,)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = vec_tar.fit_transform(df['Category'])\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10b67bc90>,\n",
       " <matplotlib.lines.Line2D at 0x10ce4b650>,\n",
       " <matplotlib.lines.Line2D at 0x10ce4b8d0>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAECCAYAAAAW+Nd4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b67bed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#each color is a question, x axis is the words, y axis is the counts (like histogram)\n",
    "plt.plot(counts[:3,:].toarray().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_words = {}\n",
    "for itrg in np.unique(targets):\n",
    "    cat = vec_tar.classes_[itrg]\n",
    "    # Pull rows for the current category, sum all rows (each element is a word)\n",
    "    icounts = counts[targets == itrg, :].sum(0).squeeze() \n",
    "    \n",
    "    # Which word counts occured >5 times\n",
    "    mask_top_words = icounts > 5\n",
    "    \n",
    "    # Turns vectors back into actual words (inverse transform - magical!)\n",
    "    top_words[cat] = vec.inverse_transform(mask_top_words)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keep words that are unique to that category\n",
    "unique_words = {}\n",
    "for cat, words in zip(top_words.keys(), top_words.values()):\n",
    "    others = top_words.copy()\n",
    "    others.pop(cat)\n",
    "    unique_words[cat] = [wrd for wrd in top_words[cat]\n",
    "                         if wrd not in np.hstack(others.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.511111111111\n",
      "0.566666666667\n",
      "0.537037037037\n",
      "0.503703703704\n",
      "0.503703703704\n",
      "0.537037037037\n",
      "0.525925925926\n",
      "0.511111111111\n",
      "0.544444444444\n",
      "0.522222222222\n",
      "Linear SVC mean score: 0.5262962962962963\n"
     ]
    }
   ],
   "source": [
    "#try SVC\n",
    "mod = LinearSVC(C=.1)\n",
    "cv = StratifiedShuffleSplit(targets, n_iter=10, test_size=.1)\n",
    "\n",
    "coefs, scores = [[] for i in range(2)]\n",
    "for tr, tt in cv:\n",
    "    mod.fit(counts[tr], targets[tr])\n",
    "    coefs.append(mod.coef_)\n",
    "    print(mod.score(counts[tt], targets[tt]))\n",
    "    scores.append(mod.score(counts[tt],targets[tt]))\n",
    "coefs = np.array(coefs).mean(0)\n",
    "\n",
    "print('Linear SVC mean score: {0}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.52962962963\n",
      "0.57037037037\n",
      "0.518518518519\n",
      "0.548148148148\n",
      "0.577777777778\n",
      "0.562962962963\n",
      "0.57037037037\n",
      "0.566666666667\n",
      "0.588888888889\n",
      "0.581481481481\n",
      "Naive Bayes mean score: 0.5438888888888889\n"
     ]
    }
   ],
   "source": [
    "#try Naive Bayes\n",
    "mod = MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
    "cv = StratifiedShuffleSplit(targets, n_iter = 10, test_size = 0.1)\n",
    "\n",
    "coefs = []\n",
    "for tr, tt in cv:\n",
    "    mod.fit(counts[tr], targets[tr])\n",
    "    coefs.append(mod.coef_)\n",
    "    print(mod.score(counts[tt], targets[tt]))\n",
    "    scores.append(mod.score(counts[tt],targets[tt]))\n",
    "coefs = np.array(coefs).mean(0)\n",
    "\n",
    "print('Naive Bayes mean score: {0}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: [array(['best', 'does', 'good', 'know', 'like', 'make', 'need', 'people',\n",
      "       'want', 'yahoo'], \n",
      "      dtype='<U13')]\n",
      "2: [array(['best', 'computer', 'does', 'know', 'use', 'want', 'web', 'windows',\n",
      "       'xa', 'yahoo'], \n",
      "      dtype='<U13')]\n",
      "3: [array(['best', 'did', 'does', 'favorite', 'know', 'like', 'movie', 'music',\n",
      "       'song', 'xa'], \n",
      "      dtype='<U13')]\n",
      "4: [array(['boyfriend', 'does', 'friend', 'girl', 'guy', 'know', 'like',\n",
      "       'love', 'really', 'want'], \n",
      "      dtype='<U13')]\n",
      "5: [array(['best', 'college', 'does', 'good', 'help', 'know', 'need', 'school',\n",
      "       'word', 'xa'], \n",
      "      dtype='<U13')]\n",
      "6: [array(['bad', 'best', 'does', 'feel', 'good', 'help', 'know', 'like',\n",
      "       'pain', 'way'], \n",
      "      dtype='<U13')]\n",
      "7: [array(['does', 'earth', 'gas', 'life', 'make', 'really', 'tell', 'theory',\n",
      "       'world', 'xa'], \n",
      "      dtype='<U13')]\n"
     ]
    }
   ],
   "source": [
    "#look only at highly weighted\n",
    "for cat, icoef in zip(vec_tar.classes_, coefs):\n",
    "    cut = np.percentile(icoef, 99)\n",
    "    important = icoef > cut\n",
    "    print('{0}: {1}'.format(cat, vec.inverse_transform(important)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
