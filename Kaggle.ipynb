{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "sns.set_palette('colorblind')\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>why are yawns contagious? when people yawn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>what is trans fat? how to reduce that? i heard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>roth ira vs 401k? what is the difference betwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>how many planes fedex has? i heard that it is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>what is the best photo slideshow creation appl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                               Text\n",
       "0         5         why are yawns contagious? when people yawn\n",
       "1         6  what is trans fat? how to reduce that? i heard...\n",
       "2         1  roth ira vs 401k? what is the difference betwe...\n",
       "3         1  how many planes fedex has? i heard that it is ...\n",
       "4         2  what is the best photo slideshow creation appl..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('newtrain.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tokenize text\n",
    "pattern = r'''(?x)    # set flag to allow verbose regexps\n",
    "     ([A-Z]\\.)+        # abbreviations, e.g. U.S.A.\n",
    "   | \\w+([-']\\w+)*        # words with optional internal hyphens\n",
    "   | \\$?\\d+(\\.\\d+)?%?  # currency and percentages, e.g. $12.40, 82%\n",
    "   | \\.\\.\\.            # ellipsis\n",
    "   | [.,;\"?():-_`]+  # these are separate tokens\n",
    " '''\n",
    "\n",
    "tokenize = lambda text: nltk.regexp_tokenize(text, pattern)\n",
    "df['Text'] = df['Text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>[why, are, yawns, contagious, ?, when, people,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>[what, is, trans, fat, ?, how, to, reduce, tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[roth, ira, vs, 401k, ?, what, is, the, differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[how, many, planes, fedex, has, ?, i, heard, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>[what, is, the, best, photo, slideshow, creati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                               Text\n",
       "0         5  [why, are, yawns, contagious, ?, when, people,...\n",
       "1         6  [what, is, trans, fat, ?, how, to, reduce, tha...\n",
       "2         1  [roth, ira, vs, 401k, ?, what, is, the, differ...\n",
       "3         1  [how, many, planes, fedex, has, ?, i, heard, t...\n",
       "4         2  [what, is, the, best, photo, slideshow, creati..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove punctuation, stopwords\n",
    "rem_chars = [p for p in string.punctuation] + list(ENGLISH_STOP_WORDS)\n",
    "#rem_chars = [p for p in string.punctuation]\n",
    "rem = lambda a: ' '.join([i for i in a if i not in rem_chars])\n",
    "#rem = lambda a: [i for i in a if i not in rem_chars]\n",
    "df['Text'] = df['Text'].apply(rem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>yawns contagious people yawn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>trans fat reduce heard tras fat bad body daily...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>roth ira vs 401k difference roth ira 401k prefer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>planes fedex heard largest airline world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>best photo slideshow creation application best...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                               Text\n",
       "0         5                       yawns contagious people yawn\n",
       "1         6  trans fat reduce heard tras fat bad body daily...\n",
       "2         1   roth ira vs 401k difference roth ira 401k prefer\n",
       "3         1           planes fedex heard largest airline world\n",
       "4         2  best photo slideshow creation application best..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lin qingxia aka brigitte lin beautiful woman chinese cinema according stephen chow http www hkentreview com 2005 features kfh kfhprem html ). true best-looking male star did make movies'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Text.iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', SGDClassifier(loss = 'hinge',penalty = 'L2'))])\n",
    "\n",
    "text_clf = text_clf.fit(df['Text'],df['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "JoblibAttributeError",
     "evalue": "JoblibAttributeError\n___________________________________________________________________________\nMultiprocessing exception:\n    ...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/runpy.py in _run_module_as_main(mod_name='IPython.kernel.__main__', alter_argv=1)\n    155     pkg_name = mod_name.rpartition('.')[0]\n    156     main_globals = sys.modules[\"__main__\"].__dict__\n    157     if alter_argv:\n    158         sys.argv[0] = fname\n    159     return _run_code(code, main_globals, None,\n--> 160                      \"__main__\", fname, loader, pkg_name)\n        fname = '/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/__main__.py'\n        loader = <_frozen_importlib.SourceFileLoader object>\n        pkg_name = 'IPython.kernel'\n    161 \n    162 def run_module(mod_name, init_globals=None,\n    163                run_name=None, alter_sys=False):\n    164     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/runpy.py in _run_code(code=<code object <module> at 0x10071bb70, file \"/Use...ite-packages/IPython/kernel/__main__.py\", line 1>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': None, '__doc__': None, '__file__': '/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/__main__.py', '__loader__': <_frozen_importlib.SourceFileLoader object>, '__name__': '__main__', '__package__': 'IPython.kernel', 'app': <module 'IPython.kernel.zmq.kernelapp' from '/Us...3/site-packages/IPython/kernel/zmq/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_fname='/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/__main__.py', mod_loader=<_frozen_importlib.SourceFileLoader object>, pkg_name='IPython.kernel')\n     68                        __file__ = mod_fname,\n     69                        __cached__ = None,\n     70                        __doc__ = None,\n     71                        __loader__ = mod_loader,\n     72                        __package__ = pkg_name)\n---> 73     exec(code, run_globals)\n        code = <code object <module> at 0x10071bb70, file \"/Use...ite-packages/IPython/kernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': None, '__doc__': None, '__file__': '/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/__main__.py', '__loader__': <_frozen_importlib.SourceFileLoader object>, '__name__': '__main__', '__package__': 'IPython.kernel', 'app': <module 'IPython.kernel.zmq.kernelapp' from '/Us...3/site-packages/IPython/kernel/zmq/kernelapp.py'>}\n     74     return run_globals\n     75 \n     76 def _run_module_code(code, init_globals=None,\n     77                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from IPython.kernel.zmq import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/config/application.py in launch_instance(cls=<class 'IPython.kernel.zmq.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    569         \n    570         If a global instance already exists, this reinitializes and starts it\n    571         \"\"\"\n    572         app = cls.instance(**kwargs)\n    573         app.initialize(argv)\n--> 574         app.start()\n        app.start = <bound method IPKernelApp.start of <IPython.kernel.zmq.kernelapp.IPKernelApp object>>\n    575 \n    576 #-----------------------------------------------------------------------------\n    577 # utility functions, for convenience\n    578 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/zmq/kernelapp.py in start(self=<IPython.kernel.zmq.kernelapp.IPKernelApp object>)\n    368     def start(self):\n    369         if self.poller is not None:\n    370             self.poller.start()\n    371         self.kernel.start()\n    372         try:\n--> 373             ioloop.IOLoop.instance().start()\n    374         except KeyboardInterrupt:\n    375             pass\n    376 \n    377 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    146             PollIOLoop.configure(ZMQIOLoop)\n    147         return PollIOLoop.instance()\n    148     \n    149     def start(self):\n    150         try:\n--> 151             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    152         except ZMQError as e:\n    153             if e.errno == ETERM:\n    154                 # quietly return on ETERM\n    155                 pass\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    805                         self._timeouts = [x for x in self._timeouts\n    806                                           if x.callback is not None]\n    807                         heapq.heapify(self._timeouts)\n    808 \n    809                 for callback in callbacks:\n--> 810                     self._run_callback(callback)\n        self._run_callback = <bound method ZMQIOLoop._run_callback of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n        callback = functools.partial(<function wrap.<locals>.null_wrapper at 0x1068c6cb0>)\n    811                 for timeout in due_timeouts:\n    812                     if timeout.callback is not None:\n    813                         self._run_callback(timeout.callback)\n    814                 # Closures may be holding on to a lot of memory, so allow\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/tornado/ioloop.py in _run_callback(self=<zmq.eventloop.ioloop.ZMQIOLoop object>, callback=functools.partial(<function wrap.<locals>.null_wrapper at 0x1068c6cb0>))\n    587         \"\"\"Runs a callback with error handling.\n    588 \n    589         For use in subclasses.\n    590         \"\"\"\n    591         try:\n--> 592             ret = callback()\n        ret = undefined\n        callback = functools.partial(<function wrap.<locals>.null_wrapper at 0x1068c6cb0>)\n    593             if ret is not None and is_future(ret):\n    594                 # Functions that return Futures typically swallow all\n    595                 # exceptions and store them in the Future.  If a Future\n    596                 # makes it out to the IOLoop, ensure its exception (if any)\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/tornado/stack_context.py in null_wrapper(*args=(), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ()\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/zmq/kernelbase.py in enter_eventloop(self=<IPython.kernel.zmq.ipkernel.IPythonKernel object>)\n    229             stream.flush(zmq.POLLOUT)\n    230         # restore default_int_handler\n    231         signal(SIGINT, default_int_handler)\n    232         while self.eventloop is not None:\n    233             try:\n--> 234                 self.eventloop(self)\n        self.eventloop = None\n        self = <IPython.kernel.zmq.ipkernel.IPythonKernel object>\n    235             except KeyboardInterrupt:\n    236                 # Ctrl-C shouldn't crash the kernel\n    237                 self.log.error(\"KeyboardInterrupt caught in kernel\")\n    238                 continue\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/zmq/eventloops.py in loop_cocoa(kernel=<IPython.kernel.zmq.ipkernel.IPythonKernel object>)\n    246                 show.mainloop()\n    247                 sys.excepthook = real_excepthook\n    248                 # use poller if mainloop returned (no windows)\n    249                 # scale by extra factor of 10, since it's a real poll\n    250                 poller.poll(10*poll_interval)\n--> 251                 kernel.do_one_iteration()\n        kernel.do_one_iteration = <bound method IPythonKernel.do_one_iteration of <IPython.kernel.zmq.ipkernel.IPythonKernel object>>\n    252             except:\n    253                 raise\n    254         except KeyboardInterrupt:\n    255             # Ctrl-C shouldn't crash the kernel\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/zmq/kernelbase.py in do_one_iteration(self=<IPython.kernel.zmq.ipkernel.IPythonKernel object>)\n    262         \"\"\"step eventloop just once\"\"\"\n    263         if self.control_stream:\n    264             self.control_stream.flush()\n    265         for stream in self.shell_streams:\n    266             # handle at most one request per iteration\n--> 267             stream.flush(zmq.POLLIN, 1)\n        stream.flush = <bound method ZMQStream.flush of <zmq.eventloop.zmqstream.ZMQStream object>>\n    268             stream.flush(zmq.POLLOUT)\n    269 \n    270 \n    271     def record_ports(self, ports):\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/zmq/eventloop/zmqstream.py in flush(self=<zmq.eventloop.zmqstream.ZMQStream object>, flag=1, limit=1)\n    340         self.poller.register(self.socket, flag)\n    341         events = self.poller.poll(0)\n    342         while events and (not limit or count < limit):\n    343             s,event = events[0]\n    344             if event & zmq.POLLIN: # receiving\n--> 345                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    346                 count += 1\n    347                 if self.socket is None:\n    348                     # break if socket was closed during callback\n    349                     break\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    460                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    461         else:\n    462             if self._recv_callback:\n    463                 callback = self._recv_callback\n    464                 # self._recv_callback = None\n--> 465                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    466                 \n    467         # self.update_state()\n    468         \n    469 \n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    402         close our socket.\"\"\"\n    403         try:\n    404             # Use a NullContext to ensure that all StackContexts are run\n    405             # inside our blanket exception handler rather than outside.\n    406             with stack_context.NullContext():\n--> 407                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    408         except:\n    409             gen_log.error(\"Uncaught exception, closing connection.\",\n    410                           exc_info=True)\n    411             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/zmq/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    247         if self.control_stream:\n    248             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    249 \n    250         def make_dispatcher(stream):\n    251             def dispatcher(msg):\n--> 252                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    253             return dispatcher\n    254 \n    255         for s in self.shell_streams:\n    256             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/zmq/kernelbase.py in dispatch_shell(self=<IPython.kernel.zmq.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.grid_search import GridSearchCV\\n#gr...id_scores_, key=lambda x: x[1]) #find best params', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'msg_id': '557B192CAFD240ED8275FE1EDE95C109', 'msg_type': 'execute_request', 'session': 'E745F92131DB4300A3ABC50EDE026100', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '557B192CAFD240ED8275FE1EDE95C109', 'msg_type': 'execute_request', 'parent_header': {}})\n    208         else:\n    209             # ensure default_int_handler during handler call\n    210             sig = signal(SIGINT, default_int_handler)\n    211             self.log.debug(\"%s: %s\", msg_type, msg)\n    212             try:\n--> 213                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <IPython.kernel.zmq.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'E745F92131DB4300A3ABC50EDE026100']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.grid_search import GridSearchCV\\n#gr...id_scores_, key=lambda x: x[1]) #find best params', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'msg_id': '557B192CAFD240ED8275FE1EDE95C109', 'msg_type': 'execute_request', 'session': 'E745F92131DB4300A3ABC50EDE026100', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '557B192CAFD240ED8275FE1EDE95C109', 'msg_type': 'execute_request', 'parent_header': {}}\n    214             except Exception:\n    215                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    216             finally:\n    217                 signal(SIGINT, sig)\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/zmq/kernelbase.py in execute_request(self=<IPython.kernel.zmq.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'E745F92131DB4300A3ABC50EDE026100'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.grid_search import GridSearchCV\\n#gr...id_scores_, key=lambda x: x[1]) #find best params', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'msg_id': '557B192CAFD240ED8275FE1EDE95C109', 'msg_type': 'execute_request', 'session': 'E745F92131DB4300A3ABC50EDE026100', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '557B192CAFD240ED8275FE1EDE95C109', 'msg_type': 'execute_request', 'parent_header': {}})\n    357         if not silent:\n    358             self.execution_count += 1\n    359             self._publish_execute_input(code, parent, self.execution_count)\n    360         \n    361         reply_content = self.do_execute(code, silent, store_history,\n--> 362                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    363 \n    364         # Flush output before sending the reply.\n    365         sys.stdout.flush()\n    366         sys.stderr.flush()\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/zmq/ipkernel.py in do_execute(self=<IPython.kernel.zmq.ipkernel.IPythonKernel object>, code='from sklearn.grid_search import GridSearchCV\\n#gr...id_scores_, key=lambda x: x[1]) #find best params', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    176 \n    177         reply_content = {}\n    178         # FIXME: the shell calls the exception handler itself.\n    179         shell._reply_content = None\n    180         try:\n--> 181             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <I....kernel.zmq.zmqshell.ZMQInteractiveShell object>>\n        code = 'from sklearn.grid_search import GridSearchCV\\n#gr...id_scores_, key=lambda x: x[1]) #find best params'\n        store_history = True\n        silent = False\n    182         except:\n    183             status = u'error'\n    184             # FIXME: this code right now isn't being used yet by default,\n    185             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/core/interactiveshell.py in run_cell(self=<IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.grid_search import GridSearchCV\\n#gr...id_scores_, key=lambda x: x[1]) #find best params', store_history=True, silent=False, shell_futures=True)\n   2866                 self.displayhook.exec_result = result\n   2867 \n   2868                 # Execute the user code\n   2869                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2870                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2871                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2872 \n   2873                 # Reset this so later displayed values do not modify the\n   2874                 # ExecutionResult\n   2875                 self.displayhook.exec_result = None\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>], cell_name='<ipython-input-51-9f63e958eb52>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2970 \n   2971         try:\n   2972             for i, node in enumerate(to_run_exec):\n   2973                 mod = ast.Module([node])\n   2974                 code = compiler(mod, cell_name, \"exec\")\n-> 2975                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <I....kernel.zmq.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x10be164b0, file \"<ipython-input-51-9f63e958eb52>\", line 9>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2976                     return True\n   2977 \n   2978             for i, node in enumerate(to_run_interactive):\n   2979                 mod = ast.Interactive([node])\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/core/interactiveshell.py in run_code(self=<IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x10be164b0, file \"<ipython-input-51-9f63e958eb52>\", line 9>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3030         outflag = 1  # happens in more places, so it's easier as default\n   3031         try:\n   3032             try:\n   3033                 self.hooks.pre_run_code_hook()\n   3034                 #rprint('Running code', repr(code_obj)) # dbg\n-> 3035                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x10be164b0, file \"<ipython-input-51-9f63e958eb52>\", line 9>\n        self.user_global_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'ENGLISH_STOP_WORDS': frozenset(['a', 'about', 'above', 'across', 'after', 'afterwards', ...]), 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', \"get_ipython().magic('matplotlib')\", \"\\nimport seaborn as sns\\nfrom matplotlib import py....set_palette('colorblind')\\nsns.set_style('white')\", 'import pandas as pd\\nimport nltk\\nimport string\\n\\nf...B\\nfrom sklearn.tree import DecisionTreeClassifier', 'import pandas as pd\\nimport nltk\\nimport string\\n\\nf...B\\nfrom sklearn.tree import DecisionTreeClassifier', 'import pandas as pd\\nimport nltk\\nimport string\\n\\nf...B\\nfrom sklearn.tree import DecisionTreeClassifier', \"df = pd.read_csv('newtrain.csv')\\ndf.head()\", \"#tokenize text\\npattern = r'''(?x)    # set flag ... pattern)\\ndf['Text'] = df['Text'].apply(tokenize)\", 'df.head()', \"#remove punctuation, stopwords\\n#rem_chars = [p f... in rem_chars]\\ndf['Text'] = df['Text'].apply(rem)\", 'df.head()', \"#remove punctuation, stopwords\\nrem_chars = [p fo... in rem_chars]\\ndf['Text'] = df['Text'].apply(rem)\", 'df.head()', \"df = pd.read_csv('newtrain.csv')\\ndf.head()\", \"#tokenize text\\npattern = r'''(?x)    # set flag ... pattern)\\ndf['Text'] = df['Text'].apply(tokenize)\", 'df.head()', \"#remove punctuation, stopwords\\nrem_chars = [p fo... in rem_chars]\\ndf['Text'] = df['Text'].apply(rem)\", 'df.head()', 'df.Text.iloc[7]', \"#vectorize data\\n#turns words into a list of vect...s = 1000)\\ncounts = vec.fit_transform(df['Text']) \", ...], 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {6:    Category                                     ...w h t   s   t h e   b e s t   p h o t o   s l ..., 8:    Category                                     ...w h t   s   t h e   b e s t   p h o t o   s l ..., 10:    Category                                     ...w h t   s   t h e   b e s t   p h o t o   s l ..., 12:    Category                                     ...w h t   s   t h e   b e s t   p h o t o   s l ..., 13:    Category                                     ...best photo slideshow creation application best..., 15:    Category                                     ...best photo slideshow creation application best..., 17:    Category                                     ...best photo slideshow creation application best..., 18: 'lin qingxia aka brigitte lin beautiful woman chi...ml ). true best-looking male star did make movies', 22: <2698x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 23: (2698, 1000), ...}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, ...}\n        self.user_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'ENGLISH_STOP_WORDS': frozenset(['a', 'about', 'above', 'across', 'after', 'afterwards', ...]), 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', \"get_ipython().magic('matplotlib')\", \"\\nimport seaborn as sns\\nfrom matplotlib import py....set_palette('colorblind')\\nsns.set_style('white')\", 'import pandas as pd\\nimport nltk\\nimport string\\n\\nf...B\\nfrom sklearn.tree import DecisionTreeClassifier', 'import pandas as pd\\nimport nltk\\nimport string\\n\\nf...B\\nfrom sklearn.tree import DecisionTreeClassifier', 'import pandas as pd\\nimport nltk\\nimport string\\n\\nf...B\\nfrom sklearn.tree import DecisionTreeClassifier', \"df = pd.read_csv('newtrain.csv')\\ndf.head()\", \"#tokenize text\\npattern = r'''(?x)    # set flag ... pattern)\\ndf['Text'] = df['Text'].apply(tokenize)\", 'df.head()', \"#remove punctuation, stopwords\\n#rem_chars = [p f... in rem_chars]\\ndf['Text'] = df['Text'].apply(rem)\", 'df.head()', \"#remove punctuation, stopwords\\nrem_chars = [p fo... in rem_chars]\\ndf['Text'] = df['Text'].apply(rem)\", 'df.head()', \"df = pd.read_csv('newtrain.csv')\\ndf.head()\", \"#tokenize text\\npattern = r'''(?x)    # set flag ... pattern)\\ndf['Text'] = df['Text'].apply(tokenize)\", 'df.head()', \"#remove punctuation, stopwords\\nrem_chars = [p fo... in rem_chars]\\ndf['Text'] = df['Text'].apply(rem)\", 'df.head()', 'df.Text.iloc[7]', \"#vectorize data\\n#turns words into a list of vect...s = 1000)\\ncounts = vec.fit_transform(df['Text']) \", ...], 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {6:    Category                                     ...w h t   s   t h e   b e s t   p h o t o   s l ..., 8:    Category                                     ...w h t   s   t h e   b e s t   p h o t o   s l ..., 10:    Category                                     ...w h t   s   t h e   b e s t   p h o t o   s l ..., 12:    Category                                     ...w h t   s   t h e   b e s t   p h o t o   s l ..., 13:    Category                                     ...best photo slideshow creation application best..., 15:    Category                                     ...best photo slideshow creation application best..., 17:    Category                                     ...best photo slideshow creation application best..., 18: 'lin qingxia aka brigitte lin beautiful woman chi...ml ). true best-looking male star did make movies', 22: <2698x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 23: (2698, 1000), ...}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, ...}\n   3036             finally:\n   3037                 # Reset our crash handler in place\n   3038                 sys.excepthook = old_excepthook\n   3039         except SystemExit as e:\n\n...........................................................................\n/Users/matar/Documents/Courses/NLP/HW/Text_Classification/<ipython-input-51-9f63e958eb52> in <module>()\n      4                'tfidf__use_idf': (True, False), #use or don't use idf\n      5                'clf__alpha': (1e-2, 1e-3)} #with different penalty params for linear svm\n      6 \n      7 gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1) #fit grid search instance\n      8 \n----> 9 gs_clf = gs_clf.fit(counts[tr], targets[tr]) #fit on one cv fold\n     10 \n     11 best_parameters, score, _ = max(gs_clf.grid_scores_, key=lambda x: x[1]) #find best params\n     12 \n     13 \n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ... score_func=None, scoring=None,\n       verbose=0), X=<2428x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 5, 2, 1]))\n    727         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    728             Target relative to X for classification or regression;\n    729             None for unsupervised learning.\n    730 \n    731         \"\"\"\n--> 732         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...score_func=None, scoring=None,\n       verbose=0)>\n        X = <2428x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        y = array([2, 0, 0, ..., 5, 2, 1])\n        self.param_grid = {'clf__alpha': (0.01, 0.001), 'tfidf__use_idf': (True, False), 'vect__ngram_range': [(1, 1), (1, 2)]}\n    733 \n    734 \n    735 class RandomizedSearchCV(BaseSearchCV):\n    736     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ... score_func=None, scoring=None,\n       verbose=0), X=<2428x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 5, 2, 1]), parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    500         )(\n    501             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    502                                     train, test, self.verbose, parameters,\n    503                                     self.fit_params, return_parameters=True,\n    504                                     error_score=self.error_score)\n--> 505                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    506                 for train, test in cv)\n    507 \n    508         # Out is a list of triplet: score, estimator, n_test_samples\n    509         n_fits = len(out)\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<itertools.islice object>)\n    661             if pre_dispatch == \"all\" or n_jobs == 1:\n    662                 # The iterable was consumed all at once by the above for loop.\n    663                 # No need to wait for async callbacks to trigger to\n    664                 # consumption.\n    665                 self._iterating = False\n--> 666             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    667             # Make sure that we get a last message telling us we are done\n    668             elapsed_time = time.time() - self._start_time\n    669             self._print('Done %3i out of %3i | elapsed: %s finished',\n    670                         (len(self._output),\n\n    ---------------------------------------------------------------------------\n    Sub-process traceback:\n    ---------------------------------------------------------------------------\n    AttributeError                                     Mon Oct 19 09:46:54 2015\nPID: 8857          Python 3.3.5: /Users/matar/anaconda/envs/py3k/bin/python\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('vect', CountVectorizer(analyze...ffle=True,\n       verbose=0, warm_start=False))]), X=<2428x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 5, 2, 1]), scorer=<function _passthrough_scorer>, train=array([ 714,  739,  750, ..., 2425, 2426, 2427]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 832, 835,\n       836, 837, 838, 847, 854, 862]), verbose=0, parameters={'clf__alpha': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1454 \n   1455     try:\n   1456         if y_train is None:\n   1457             estimator.fit(X_train, **fit_params)\n   1458         else:\n-> 1459             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...fle=True,\n       verbose=0, warm_start=False))])>\n        X_train = <1616x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        y_train = array([5, 4, 5, ..., 5, 2, 1])\n        fit_params = {}\n   1460 \n   1461     except Exception as e:\n   1462         if error_score == 'raise':\n   1463             raise\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('vect', CountVectorizer(analyze...ffle=True,\n       verbose=0, warm_start=False))]), X=<1616x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([5, 4, 5, ..., 5, 2, 1]), **fit_params={})\n    135             pipeline.\n    136         y : iterable, default=None\n    137             Training targets. Must fulfill label requirements for all steps of\n    138             the pipeline.\n    139         \"\"\"\n--> 140         Xt, fit_params = self._pre_transform(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._pre_transform = <bound method Pipeline._pre_transform of Pipelin...fle=True,\n       verbose=0, warm_start=False))])>\n        X = <1616x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        y = array([5, 4, 5, ..., 5, 2, 1])\n    141         self.steps[-1][-1].fit(Xt, y, **fit_params)\n    142         return self\n    143 \n    144     def fit_transform(self, X, y=None, **fit_params):\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/pipeline.py in _pre_transform(self=Pipeline(steps=[('vect', CountVectorizer(analyze...ffle=True,\n       verbose=0, warm_start=False))]), X=<1616x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([5, 4, 5, ..., 5, 2, 1]), **fit_params={})\n    116             step, param = pname.split('__', 1)\n    117             fit_params_steps[step][param] = pval\n    118         Xt = X\n    119         for name, transform in self.steps[:-1]:\n    120             if hasattr(transform, \"fit_transform\"):\n--> 121                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n        Xt = <1616x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        transform.fit_transform = <bound method CountVectorizer.fit_transform of C...w+\\\\b',\n        tokenizer=None, vocabulary=None)>\n        y = array([5, 4, 5, ..., 5, 2, 1])\n        fit_params_steps = {'clf': {}, 'tfidf': {}, 'vect': {}}\n        name = 'vect'\n    122             else:\n    123                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    124                               .transform(Xt)\n    125         return Xt, fit_params_steps[self.steps[-1][0]]\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), raw_documents=<1616x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([5, 4, 5, ..., 5, 2, 1]))\n    799         max_df = self.max_df\n    800         min_df = self.min_df\n    801         max_features = self.max_features\n    802 \n    803         vocabulary, X = self._count_vocab(raw_documents,\n--> 804                                           self.fixed_vocabulary_)\n        self.fixed_vocabulary_ = False\n    805 \n    806         if self.binary:\n    807             X.data.fill(1)\n    808 \n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/feature_extraction/text.py in _count_vocab(self=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), raw_documents=<1616x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, fixed_vocab=False)\n    734         analyze = self.build_analyzer()\n    735         j_indices = _make_int_array()\n    736         indptr = _make_int_array()\n    737         indptr.append(0)\n    738         for doc in raw_documents:\n--> 739             for feature in analyze(doc):\n        feature = undefined\n        analyze = <function VectorizerMixin.build_analyzer.<locals>.<lambda>>\n        doc = <1x1000 sparse matrix of type '<class 'numpy.int... stored elements in Compressed Sparse Row format>\n    740                 try:\n    741                     j_indices.append(vocabulary[feature])\n    742                 except KeyError:\n    743                     # Ignore out-of-vocabulary items for fixed_vocab=True\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/feature_extraction/text.py in <lambda>(doc=<1x1000 sparse matrix of type '<class 'numpy.int... stored elements in Compressed Sparse Row format>)\n    231         elif self.analyzer == 'word':\n    232             stop_words = self.get_stop_words()\n    233             tokenize = self.build_tokenizer()\n    234 \n    235             return lambda doc: self._word_ngrams(\n--> 236                 tokenize(preprocess(self.decode(doc))), stop_words)\n        doc = <1x1000 sparse matrix of type '<class 'numpy.int... stored elements in Compressed Sparse Row format>\n    237 \n    238         else:\n    239             raise ValueError('%s is not a valid tokenization scheme/analyzer' %\n    240                              self.analyzer)\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/feature_extraction/text.py in <lambda>(x=<1x1000 sparse matrix of type '<class 'numpy.int... stored elements in Compressed Sparse Row format>)\n    197         else:\n    198             raise ValueError('Invalid value for \"strip_accents\": %s' %\n    199                              self.strip_accents)\n    200 \n    201         if self.lowercase:\n--> 202             return lambda x: strip_accents(x.lower())\n        x = <1x1000 sparse matrix of type '<class 'numpy.int... stored elements in Compressed Sparse Row format>\n        x.lower = undefined\n    203         else:\n    204             return strip_accents\n    205 \n    206     def build_tokenizer(self):\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/scipy/sparse/base.py in __getattr__(self=<1x1000 sparse matrix of type '<class 'numpy.int... stored elements in Compressed Sparse Row format>, attr='lower')\n    503         elif attr == 'imag':\n    504             return self._imag()\n    505         elif attr == 'size':\n    506             return self.getnnz()\n    507         else:\n--> 508             raise AttributeError(attr + \" not found\")\n        attr = 'lower'\n    509 \n    510     def transpose(self):\n    511         return self.tocsr().transpose()\n    512 \n\nAttributeError: lower not found\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/matar/anaconda/envs/py3k/lib/python3.3/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nAttributeError                                     Mon Oct 19 09:46:54 2015\nPID: 8857          Python 3.3.5: /Users/matar/anaconda/envs/py3k/bin/python\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('vect', CountVectorizer(analyze...ffle=True,\n       verbose=0, warm_start=False))]), X=<2428x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 5, 2, 1]), scorer=<function _passthrough_scorer>, train=array([ 714,  739,  750, ..., 2425, 2426, 2427]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 832, 835,\n       836, 837, 838, 847, 854, 862]), verbose=0, parameters={'clf__alpha': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1454 \n   1455     try:\n   1456         if y_train is None:\n   1457             estimator.fit(X_train, **fit_params)\n   1458         else:\n-> 1459             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...fle=True,\n       verbose=0, warm_start=False))])>\n        X_train = <1616x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        y_train = array([5, 4, 5, ..., 5, 2, 1])\n        fit_params = {}\n   1460 \n   1461     except Exception as e:\n   1462         if error_score == 'raise':\n   1463             raise\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('vect', CountVectorizer(analyze...ffle=True,\n       verbose=0, warm_start=False))]), X=<1616x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([5, 4, 5, ..., 5, 2, 1]), **fit_params={})\n    135             pipeline.\n    136         y : iterable, default=None\n    137             Training targets. Must fulfill label requirements for all steps of\n    138             the pipeline.\n    139         \"\"\"\n--> 140         Xt, fit_params = self._pre_transform(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._pre_transform = <bound method Pipeline._pre_transform of Pipelin...fle=True,\n       verbose=0, warm_start=False))])>\n        X = <1616x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        y = array([5, 4, 5, ..., 5, 2, 1])\n    141         self.steps[-1][-1].fit(Xt, y, **fit_params)\n    142         return self\n    143 \n    144     def fit_transform(self, X, y=None, **fit_params):\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/pipeline.py in _pre_transform(self=Pipeline(steps=[('vect', CountVectorizer(analyze...ffle=True,\n       verbose=0, warm_start=False))]), X=<1616x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([5, 4, 5, ..., 5, 2, 1]), **fit_params={})\n    116             step, param = pname.split('__', 1)\n    117             fit_params_steps[step][param] = pval\n    118         Xt = X\n    119         for name, transform in self.steps[:-1]:\n    120             if hasattr(transform, \"fit_transform\"):\n--> 121                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n        Xt = <1616x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        transform.fit_transform = <bound method CountVectorizer.fit_transform of C...w+\\\\b',\n        tokenizer=None, vocabulary=None)>\n        y = array([5, 4, 5, ..., 5, 2, 1])\n        fit_params_steps = {'clf': {}, 'tfidf': {}, 'vect': {}}\n        name = 'vect'\n    122             else:\n    123                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    124                               .transform(Xt)\n    125         return Xt, fit_params_steps[self.steps[-1][0]]\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), raw_documents=<1616x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([5, 4, 5, ..., 5, 2, 1]))\n    799         max_df = self.max_df\n    800         min_df = self.min_df\n    801         max_features = self.max_features\n    802 \n    803         vocabulary, X = self._count_vocab(raw_documents,\n--> 804                                           self.fixed_vocabulary_)\n        self.fixed_vocabulary_ = False\n    805 \n    806         if self.binary:\n    807             X.data.fill(1)\n    808 \n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/feature_extraction/text.py in _count_vocab(self=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), raw_documents=<1616x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, fixed_vocab=False)\n    734         analyze = self.build_analyzer()\n    735         j_indices = _make_int_array()\n    736         indptr = _make_int_array()\n    737         indptr.append(0)\n    738         for doc in raw_documents:\n--> 739             for feature in analyze(doc):\n        feature = undefined\n        analyze = <function VectorizerMixin.build_analyzer.<locals>.<lambda>>\n        doc = <1x1000 sparse matrix of type '<class 'numpy.int... stored elements in Compressed Sparse Row format>\n    740                 try:\n    741                     j_indices.append(vocabulary[feature])\n    742                 except KeyError:\n    743                     # Ignore out-of-vocabulary items for fixed_vocab=True\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/feature_extraction/text.py in <lambda>(doc=<1x1000 sparse matrix of type '<class 'numpy.int... stored elements in Compressed Sparse Row format>)\n    231         elif self.analyzer == 'word':\n    232             stop_words = self.get_stop_words()\n    233             tokenize = self.build_tokenizer()\n    234 \n    235             return lambda doc: self._word_ngrams(\n--> 236                 tokenize(preprocess(self.decode(doc))), stop_words)\n        doc = <1x1000 sparse matrix of type '<class 'numpy.int... stored elements in Compressed Sparse Row format>\n    237 \n    238         else:\n    239             raise ValueError('%s is not a valid tokenization scheme/analyzer' %\n    240                              self.analyzer)\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/feature_extraction/text.py in <lambda>(x=<1x1000 sparse matrix of type '<class 'numpy.int... stored elements in Compressed Sparse Row format>)\n    197         else:\n    198             raise ValueError('Invalid value for \"strip_accents\": %s' %\n    199                              self.strip_accents)\n    200 \n    201         if self.lowercase:\n--> 202             return lambda x: strip_accents(x.lower())\n        x = <1x1000 sparse matrix of type '<class 'numpy.int... stored elements in Compressed Sparse Row format>\n        x.lower = undefined\n    203         else:\n    204             return strip_accents\n    205 \n    206     def build_tokenizer(self):\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/scipy/sparse/base.py in __getattr__(self=<1x1000 sparse matrix of type '<class 'numpy.int... stored elements in Compressed Sparse Row format>, attr='lower')\n    503         elif attr == 'imag':\n    504             return self._imag()\n    505         elif attr == 'size':\n    506             return self.getnnz()\n    507         else:\n--> 508             raise AttributeError(attr + \" not found\")\n        attr = 'lower'\n    509 \n    510     def transpose(self):\n    511         return self.tocsr().transpose()\n    512 \n\nAttributeError: lower not found\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-9f63e958eb52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgs_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#fit grid search instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgs_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#fit on one cv fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mbest_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#find best params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \"\"\"\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    503\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 505\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m                 for train, test in cv)\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    664\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    547\u001b[0m                         \u001b[0;31m# Convert this to a JoblibException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                         \u001b[0mexception_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mk_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibAttributeError\u001b[0m: JoblibAttributeError\n___________________________________________________________________________\nMultiprocessing exception:\n    ...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/runpy.py in _run_module_as_main(mod_name='IPython.kernel.__main__', alter_argv=1)\n    155     pkg_name = mod_name.rpartition('.')[0]\n    156     main_globals = sys.modules[\"__main__\"].__dict__\n    157     if alter_argv:\n    158         sys.argv[0] = fname\n    159     return _run_code(code, main_globals, None,\n--> 160                      \"__main__\", fname, loader, pkg_name)\n        fname = '/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/__main__.py'\n        loader = <_frozen_importlib.SourceFileLoader object>\n        pkg_name = 'IPython.kernel'\n    161 \n    162 def run_module(mod_name, init_globals=None,\n    163                run_name=None, alter_sys=False):\n    164     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/runpy.py in _run_code(code=<code object <module> at 0x10071bb70, file \"/Use...ite-packages/IPython/kernel/__main__.py\", line 1>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': None, '__doc__': None, '__file__': '/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/__main__.py', '__loader__': <_frozen_importlib.SourceFileLoader object>, '__name__': '__main__', '__package__': 'IPython.kernel', 'app': <module 'IPython.kernel.zmq.kernelapp' from '/Us...3/site-packages/IPython/kernel/zmq/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_fname='/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/__main__.py', mod_loader=<_frozen_importlib.SourceFileLoader object>, pkg_name='IPython.kernel')\n     68                        __file__ = mod_fname,\n     69                        __cached__ = None,\n     70                        __doc__ = None,\n     71                        __loader__ = mod_loader,\n     72                        __package__ = pkg_name)\n---> 73     exec(code, run_globals)\n        code = <code object <module> at 0x10071bb70, file \"/Use...ite-packages/IPython/kernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': None, '__doc__': None, '__file__': '/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/__main__.py', '__loader__': <_frozen_importlib.SourceFileLoader object>, '__name__': '__main__', '__package__': 'IPython.kernel', 'app': <module 'IPython.kernel.zmq.kernelapp' from '/Us...3/site-packages/IPython/kernel/zmq/kernelapp.py'>}\n     74     return run_globals\n     75 \n     76 def _run_module_code(code, init_globals=None,\n     77                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from IPython.kernel.zmq import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/config/application.py in launch_instance(cls=<class 'IPython.kernel.zmq.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    569         \n    570         If a global instance already exists, this reinitializes and starts it\n    571         \"\"\"\n    572         app = cls.instance(**kwargs)\n    573         app.initialize(argv)\n--> 574         app.start()\n        app.start = <bound method IPKernelApp.start of <IPython.kernel.zmq.kernelapp.IPKernelApp object>>\n    575 \n    576 #-----------------------------------------------------------------------------\n    577 # utility functions, for convenience\n    578 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/zmq/kernelapp.py in start(self=<IPython.kernel.zmq.kernelapp.IPKernelApp object>)\n    368     def start(self):\n    369         if self.poller is not None:\n    370             self.poller.start()\n    371         self.kernel.start()\n    372         try:\n--> 373             ioloop.IOLoop.instance().start()\n    374         except KeyboardInterrupt:\n    375             pass\n    376 \n    377 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    146             PollIOLoop.configure(ZMQIOLoop)\n    147         return PollIOLoop.instance()\n    148     \n    149     def start(self):\n    150         try:\n--> 151             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    152         except ZMQError as e:\n    153             if e.errno == ETERM:\n    154                 # quietly return on ETERM\n    155                 pass\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    805                         self._timeouts = [x for x in self._timeouts\n    806                                           if x.callback is not None]\n    807                         heapq.heapify(self._timeouts)\n    808 \n    809                 for callback in callbacks:\n--> 810                     self._run_callback(callback)\n        self._run_callback = <bound method ZMQIOLoop._run_callback of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n        callback = functools.partial(<function wrap.<locals>.null_wrapper at 0x1068c6cb0>)\n    811                 for timeout in due_timeouts:\n    812                     if timeout.callback is not None:\n    813                         self._run_callback(timeout.callback)\n    814                 # Closures may be holding on to a lot of memory, so allow\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/tornado/ioloop.py in _run_callback(self=<zmq.eventloop.ioloop.ZMQIOLoop object>, callback=functools.partial(<function wrap.<locals>.null_wrapper at 0x1068c6cb0>))\n    587         \"\"\"Runs a callback with error handling.\n    588 \n    589         For use in subclasses.\n    590         \"\"\"\n    591         try:\n--> 592             ret = callback()\n        ret = undefined\n        callback = functools.partial(<function wrap.<locals>.null_wrapper at 0x1068c6cb0>)\n    593             if ret is not None and is_future(ret):\n    594                 # Functions that return Futures typically swallow all\n    595                 # exceptions and store them in the Future.  If a Future\n    596                 # makes it out to the IOLoop, ensure its exception (if any)\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/tornado/stack_context.py in null_wrapper(*args=(), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ()\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/zmq/kernelbase.py in enter_eventloop(self=<IPython.kernel.zmq.ipkernel.IPythonKernel object>)\n    229             stream.flush(zmq.POLLOUT)\n    230         # restore default_int_handler\n    231         signal(SIGINT, default_int_handler)\n    232         while self.eventloop is not None:\n    233             try:\n--> 234                 self.eventloop(self)\n        self.eventloop = None\n        self = <IPython.kernel.zmq.ipkernel.IPythonKernel object>\n    235             except KeyboardInterrupt:\n    236                 # Ctrl-C shouldn't crash the kernel\n    237                 self.log.error(\"KeyboardInterrupt caught in kernel\")\n    238                 continue\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/zmq/eventloops.py in loop_cocoa(kernel=<IPython.kernel.zmq.ipkernel.IPythonKernel object>)\n    246                 show.mainloop()\n    247                 sys.excepthook = real_excepthook\n    248                 # use poller if mainloop returned (no windows)\n    249                 # scale by extra factor of 10, since it's a real poll\n    250                 poller.poll(10*poll_interval)\n--> 251                 kernel.do_one_iteration()\n        kernel.do_one_iteration = <bound method IPythonKernel.do_one_iteration of <IPython.kernel.zmq.ipkernel.IPythonKernel object>>\n    252             except:\n    253                 raise\n    254         except KeyboardInterrupt:\n    255             # Ctrl-C shouldn't crash the kernel\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/zmq/kernelbase.py in do_one_iteration(self=<IPython.kernel.zmq.ipkernel.IPythonKernel object>)\n    262         \"\"\"step eventloop just once\"\"\"\n    263         if self.control_stream:\n    264             self.control_stream.flush()\n    265         for stream in self.shell_streams:\n    266             # handle at most one request per iteration\n--> 267             stream.flush(zmq.POLLIN, 1)\n        stream.flush = <bound method ZMQStream.flush of <zmq.eventloop.zmqstream.ZMQStream object>>\n    268             stream.flush(zmq.POLLOUT)\n    269 \n    270 \n    271     def record_ports(self, ports):\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/zmq/eventloop/zmqstream.py in flush(self=<zmq.eventloop.zmqstream.ZMQStream object>, flag=1, limit=1)\n    340         self.poller.register(self.socket, flag)\n    341         events = self.poller.poll(0)\n    342         while events and (not limit or count < limit):\n    343             s,event = events[0]\n    344             if event & zmq.POLLIN: # receiving\n--> 345                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    346                 count += 1\n    347                 if self.socket is None:\n    348                     # break if socket was closed during callback\n    349                     break\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    460                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    461         else:\n    462             if self._recv_callback:\n    463                 callback = self._recv_callback\n    464                 # self._recv_callback = None\n--> 465                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    466                 \n    467         # self.update_state()\n    468         \n    469 \n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    402         close our socket.\"\"\"\n    403         try:\n    404             # Use a NullContext to ensure that all StackContexts are run\n    405             # inside our blanket exception handler rather than outside.\n    406             with stack_context.NullContext():\n--> 407                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    408         except:\n    409             gen_log.error(\"Uncaught exception, closing connection.\",\n    410                           exc_info=True)\n    411             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/zmq/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    247         if self.control_stream:\n    248             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    249 \n    250         def make_dispatcher(stream):\n    251             def dispatcher(msg):\n--> 252                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    253             return dispatcher\n    254 \n    255         for s in self.shell_streams:\n    256             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/zmq/kernelbase.py in dispatch_shell(self=<IPython.kernel.zmq.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.grid_search import GridSearchCV\\n#gr...id_scores_, key=lambda x: x[1]) #find best params', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'msg_id': '557B192CAFD240ED8275FE1EDE95C109', 'msg_type': 'execute_request', 'session': 'E745F92131DB4300A3ABC50EDE026100', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '557B192CAFD240ED8275FE1EDE95C109', 'msg_type': 'execute_request', 'parent_header': {}})\n    208         else:\n    209             # ensure default_int_handler during handler call\n    210             sig = signal(SIGINT, default_int_handler)\n    211             self.log.debug(\"%s: %s\", msg_type, msg)\n    212             try:\n--> 213                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <IPython.kernel.zmq.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'E745F92131DB4300A3ABC50EDE026100']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.grid_search import GridSearchCV\\n#gr...id_scores_, key=lambda x: x[1]) #find best params', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'msg_id': '557B192CAFD240ED8275FE1EDE95C109', 'msg_type': 'execute_request', 'session': 'E745F92131DB4300A3ABC50EDE026100', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '557B192CAFD240ED8275FE1EDE95C109', 'msg_type': 'execute_request', 'parent_header': {}}\n    214             except Exception:\n    215                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    216             finally:\n    217                 signal(SIGINT, sig)\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/zmq/kernelbase.py in execute_request(self=<IPython.kernel.zmq.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'E745F92131DB4300A3ABC50EDE026100'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.grid_search import GridSearchCV\\n#gr...id_scores_, key=lambda x: x[1]) #find best params', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'msg_id': '557B192CAFD240ED8275FE1EDE95C109', 'msg_type': 'execute_request', 'session': 'E745F92131DB4300A3ABC50EDE026100', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '557B192CAFD240ED8275FE1EDE95C109', 'msg_type': 'execute_request', 'parent_header': {}})\n    357         if not silent:\n    358             self.execution_count += 1\n    359             self._publish_execute_input(code, parent, self.execution_count)\n    360         \n    361         reply_content = self.do_execute(code, silent, store_history,\n--> 362                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    363 \n    364         # Flush output before sending the reply.\n    365         sys.stdout.flush()\n    366         sys.stderr.flush()\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/kernel/zmq/ipkernel.py in do_execute(self=<IPython.kernel.zmq.ipkernel.IPythonKernel object>, code='from sklearn.grid_search import GridSearchCV\\n#gr...id_scores_, key=lambda x: x[1]) #find best params', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    176 \n    177         reply_content = {}\n    178         # FIXME: the shell calls the exception handler itself.\n    179         shell._reply_content = None\n    180         try:\n--> 181             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <I....kernel.zmq.zmqshell.ZMQInteractiveShell object>>\n        code = 'from sklearn.grid_search import GridSearchCV\\n#gr...id_scores_, key=lambda x: x[1]) #find best params'\n        store_history = True\n        silent = False\n    182         except:\n    183             status = u'error'\n    184             # FIXME: this code right now isn't being used yet by default,\n    185             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/core/interactiveshell.py in run_cell(self=<IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.grid_search import GridSearchCV\\n#gr...id_scores_, key=lambda x: x[1]) #find best params', store_history=True, silent=False, shell_futures=True)\n   2866                 self.displayhook.exec_result = result\n   2867 \n   2868                 # Execute the user code\n   2869                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2870                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2871                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2872 \n   2873                 # Reset this so later displayed values do not modify the\n   2874                 # ExecutionResult\n   2875                 self.displayhook.exec_result = None\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>], cell_name='<ipython-input-51-9f63e958eb52>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2970 \n   2971         try:\n   2972             for i, node in enumerate(to_run_exec):\n   2973                 mod = ast.Module([node])\n   2974                 code = compiler(mod, cell_name, \"exec\")\n-> 2975                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <I....kernel.zmq.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x10be164b0, file \"<ipython-input-51-9f63e958eb52>\", line 9>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2976                     return True\n   2977 \n   2978             for i, node in enumerate(to_run_interactive):\n   2979                 mod = ast.Interactive([node])\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/IPython/core/interactiveshell.py in run_code(self=<IPython.kernel.zmq.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x10be164b0, file \"<ipython-input-51-9f63e958eb52>\", line 9>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3030         outflag = 1  # happens in more places, so it's easier as default\n   3031         try:\n   3032             try:\n   3033                 self.hooks.pre_run_code_hook()\n   3034                 #rprint('Running code', repr(code_obj)) # dbg\n-> 3035                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x10be164b0, file \"<ipython-input-51-9f63e958eb52>\", line 9>\n        self.user_global_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'ENGLISH_STOP_WORDS': frozenset(['a', 'about', 'above', 'across', 'after', 'afterwards', ...]), 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', \"get_ipython().magic('matplotlib')\", \"\\nimport seaborn as sns\\nfrom matplotlib import py....set_palette('colorblind')\\nsns.set_style('white')\", 'import pandas as pd\\nimport nltk\\nimport string\\n\\nf...B\\nfrom sklearn.tree import DecisionTreeClassifier', 'import pandas as pd\\nimport nltk\\nimport string\\n\\nf...B\\nfrom sklearn.tree import DecisionTreeClassifier', 'import pandas as pd\\nimport nltk\\nimport string\\n\\nf...B\\nfrom sklearn.tree import DecisionTreeClassifier', \"df = pd.read_csv('newtrain.csv')\\ndf.head()\", \"#tokenize text\\npattern = r'''(?x)    # set flag ... pattern)\\ndf['Text'] = df['Text'].apply(tokenize)\", 'df.head()', \"#remove punctuation, stopwords\\n#rem_chars = [p f... in rem_chars]\\ndf['Text'] = df['Text'].apply(rem)\", 'df.head()', \"#remove punctuation, stopwords\\nrem_chars = [p fo... in rem_chars]\\ndf['Text'] = df['Text'].apply(rem)\", 'df.head()', \"df = pd.read_csv('newtrain.csv')\\ndf.head()\", \"#tokenize text\\npattern = r'''(?x)    # set flag ... pattern)\\ndf['Text'] = df['Text'].apply(tokenize)\", 'df.head()', \"#remove punctuation, stopwords\\nrem_chars = [p fo... in rem_chars]\\ndf['Text'] = df['Text'].apply(rem)\", 'df.head()', 'df.Text.iloc[7]', \"#vectorize data\\n#turns words into a list of vect...s = 1000)\\ncounts = vec.fit_transform(df['Text']) \", ...], 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {6:    Category                                     ...w h t   s   t h e   b e s t   p h o t o   s l ..., 8:    Category                                     ...w h t   s   t h e   b e s t   p h o t o   s l ..., 10:    Category                                     ...w h t   s   t h e   b e s t   p h o t o   s l ..., 12:    Category                                     ...w h t   s   t h e   b e s t   p h o t o   s l ..., 13:    Category                                     ...best photo slideshow creation application best..., 15:    Category                                     ...best photo slideshow creation application best..., 17:    Category                                     ...best photo slideshow creation application best..., 18: 'lin qingxia aka brigitte lin beautiful woman chi...ml ). true best-looking male star did make movies', 22: <2698x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 23: (2698, 1000), ...}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, ...}\n        self.user_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'ENGLISH_STOP_WORDS': frozenset(['a', 'about', 'above', 'across', 'after', 'afterwards', ...]), 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', \"get_ipython().magic('matplotlib')\", \"\\nimport seaborn as sns\\nfrom matplotlib import py....set_palette('colorblind')\\nsns.set_style('white')\", 'import pandas as pd\\nimport nltk\\nimport string\\n\\nf...B\\nfrom sklearn.tree import DecisionTreeClassifier', 'import pandas as pd\\nimport nltk\\nimport string\\n\\nf...B\\nfrom sklearn.tree import DecisionTreeClassifier', 'import pandas as pd\\nimport nltk\\nimport string\\n\\nf...B\\nfrom sklearn.tree import DecisionTreeClassifier', \"df = pd.read_csv('newtrain.csv')\\ndf.head()\", \"#tokenize text\\npattern = r'''(?x)    # set flag ... pattern)\\ndf['Text'] = df['Text'].apply(tokenize)\", 'df.head()', \"#remove punctuation, stopwords\\n#rem_chars = [p f... in rem_chars]\\ndf['Text'] = df['Text'].apply(rem)\", 'df.head()', \"#remove punctuation, stopwords\\nrem_chars = [p fo... in rem_chars]\\ndf['Text'] = df['Text'].apply(rem)\", 'df.head()', \"df = pd.read_csv('newtrain.csv')\\ndf.head()\", \"#tokenize text\\npattern = r'''(?x)    # set flag ... pattern)\\ndf['Text'] = df['Text'].apply(tokenize)\", 'df.head()', \"#remove punctuation, stopwords\\nrem_chars = [p fo... in rem_chars]\\ndf['Text'] = df['Text'].apply(rem)\", 'df.head()', 'df.Text.iloc[7]', \"#vectorize data\\n#turns words into a list of vect...s = 1000)\\ncounts = vec.fit_transform(df['Text']) \", ...], 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {6:    Category                                     ...w h t   s   t h e   b e s t   p h o t o   s l ..., 8:    Category                                     ...w h t   s   t h e   b e s t   p h o t o   s l ..., 10:    Category                                     ...w h t   s   t h e   b e s t   p h o t o   s l ..., 12:    Category                                     ...w h t   s   t h e   b e s t   p h o t o   s l ..., 13:    Category                                     ...best photo slideshow creation application best..., 15:    Category                                     ...best photo slideshow creation application best..., 17:    Category                                     ...best photo slideshow creation application best..., 18: 'lin qingxia aka brigitte lin beautiful woman chi...ml ). true best-looking male star did make movies', 22: <2698x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 23: (2698, 1000), ...}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, ...}\n   3036             finally:\n   3037                 # Reset our crash handler in place\n   3038                 sys.excepthook = old_excepthook\n   3039         except SystemExit as e:\n\n...........................................................................\n/Users/matar/Documents/Courses/NLP/HW/Text_Classification/<ipython-input-51-9f63e958eb52> in <module>()\n      4                'tfidf__use_idf': (True, False), #use or don't use idf\n      5                'clf__alpha': (1e-2, 1e-3)} #with different penalty params for linear svm\n      6 \n      7 gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1) #fit grid search instance\n      8 \n----> 9 gs_clf = gs_clf.fit(counts[tr], targets[tr]) #fit on one cv fold\n     10 \n     11 best_parameters, score, _ = max(gs_clf.grid_scores_, key=lambda x: x[1]) #find best params\n     12 \n     13 \n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ... score_func=None, scoring=None,\n       verbose=0), X=<2428x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 5, 2, 1]))\n    727         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    728             Target relative to X for classification or regression;\n    729             None for unsupervised learning.\n    730 \n    731         \"\"\"\n--> 732         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...score_func=None, scoring=None,\n       verbose=0)>\n        X = <2428x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        y = array([2, 0, 0, ..., 5, 2, 1])\n        self.param_grid = {'clf__alpha': (0.01, 0.001), 'tfidf__use_idf': (True, False), 'vect__ngram_range': [(1, 1), (1, 2)]}\n    733 \n    734 \n    735 class RandomizedSearchCV(BaseSearchCV):\n    736     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ... score_func=None, scoring=None,\n       verbose=0), X=<2428x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 5, 2, 1]), parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    500         )(\n    501             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    502                                     train, test, self.verbose, parameters,\n    503                                     self.fit_params, return_parameters=True,\n    504                                     error_score=self.error_score)\n--> 505                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    506                 for train, test in cv)\n    507 \n    508         # Out is a list of triplet: score, estimator, n_test_samples\n    509         n_fits = len(out)\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<itertools.islice object>)\n    661             if pre_dispatch == \"all\" or n_jobs == 1:\n    662                 # The iterable was consumed all at once by the above for loop.\n    663                 # No need to wait for async callbacks to trigger to\n    664                 # consumption.\n    665                 self._iterating = False\n--> 666             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    667             # Make sure that we get a last message telling us we are done\n    668             elapsed_time = time.time() - self._start_time\n    669             self._print('Done %3i out of %3i | elapsed: %s finished',\n    670                         (len(self._output),\n\n    ---------------------------------------------------------------------------\n    Sub-process traceback:\n    ---------------------------------------------------------------------------\n    AttributeError                                     Mon Oct 19 09:46:54 2015\nPID: 8857          Python 3.3.5: /Users/matar/anaconda/envs/py3k/bin/python\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('vect', CountVectorizer(analyze...ffle=True,\n       verbose=0, warm_start=False))]), X=<2428x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([2, 0, 0, ..., 5, 2, 1]), scorer=<function _passthrough_scorer>, train=array([ 714,  739,  750, ..., 2425, 2426, 2427]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 832, 835,\n       836, 837, 838, 847, 854, 862]), verbose=0, parameters={'clf__alpha': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1454 \n   1455     try:\n   1456         if y_train is None:\n   1457             estimator.fit(X_train, **fit_params)\n   1458         else:\n-> 1459             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...fle=True,\n       verbose=0, warm_start=False))])>\n        X_train = <1616x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        y_train = array([5, 4, 5, ..., 5, 2, 1])\n        fit_params = {}\n   1460 \n   1461     except Exception as e:\n   1462         if error_score == 'raise':\n   1463             raise\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('vect', CountVectorizer(analyze...ffle=True,\n       verbose=0, warm_start=False))]), X=<1616x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([5, 4, 5, ..., 5, 2, 1]), **fit_params={})\n    135             pipeline.\n    136         y : iterable, default=None\n    137             Training targets. Must fulfill label requirements for all steps of\n    138             the pipeline.\n    139         \"\"\"\n--> 140         Xt, fit_params = self._pre_transform(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._pre_transform = <bound method Pipeline._pre_transform of Pipelin...fle=True,\n       verbose=0, warm_start=False))])>\n        X = <1616x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        y = array([5, 4, 5, ..., 5, 2, 1])\n    141         self.steps[-1][-1].fit(Xt, y, **fit_params)\n    142         return self\n    143 \n    144     def fit_transform(self, X, y=None, **fit_params):\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/pipeline.py in _pre_transform(self=Pipeline(steps=[('vect', CountVectorizer(analyze...ffle=True,\n       verbose=0, warm_start=False))]), X=<1616x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([5, 4, 5, ..., 5, 2, 1]), **fit_params={})\n    116             step, param = pname.split('__', 1)\n    117             fit_params_steps[step][param] = pval\n    118         Xt = X\n    119         for name, transform in self.steps[:-1]:\n    120             if hasattr(transform, \"fit_transform\"):\n--> 121                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n        Xt = <1616x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        transform.fit_transform = <bound method CountVectorizer.fit_transform of C...w+\\\\b',\n        tokenizer=None, vocabulary=None)>\n        y = array([5, 4, 5, ..., 5, 2, 1])\n        fit_params_steps = {'clf': {}, 'tfidf': {}, 'vect': {}}\n        name = 'vect'\n    122             else:\n    123                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    124                               .transform(Xt)\n    125         return Xt, fit_params_steps[self.steps[-1][0]]\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), raw_documents=<1616x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=array([5, 4, 5, ..., 5, 2, 1]))\n    799         max_df = self.max_df\n    800         min_df = self.min_df\n    801         max_features = self.max_features\n    802 \n    803         vocabulary, X = self._count_vocab(raw_documents,\n--> 804                                           self.fixed_vocabulary_)\n        self.fixed_vocabulary_ = False\n    805 \n    806         if self.binary:\n    807             X.data.fill(1)\n    808 \n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/feature_extraction/text.py in _count_vocab(self=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), raw_documents=<1616x1000 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, fixed_vocab=False)\n    734         analyze = self.build_analyzer()\n    735         j_indices = _make_int_array()\n    736         indptr = _make_int_array()\n    737         indptr.append(0)\n    738         for doc in raw_documents:\n--> 739             for feature in analyze(doc):\n        feature = undefined\n        analyze = <function VectorizerMixin.build_analyzer.<locals>.<lambda>>\n        doc = <1x1000 sparse matrix of type '<class 'numpy.int... stored elements in Compressed Sparse Row format>\n    740                 try:\n    741                     j_indices.append(vocabulary[feature])\n    742                 except KeyError:\n    743                     # Ignore out-of-vocabulary items for fixed_vocab=True\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/feature_extraction/text.py in <lambda>(doc=<1x1000 sparse matrix of type '<class 'numpy.int... stored elements in Compressed Sparse Row format>)\n    231         elif self.analyzer == 'word':\n    232             stop_words = self.get_stop_words()\n    233             tokenize = self.build_tokenizer()\n    234 \n    235             return lambda doc: self._word_ngrams(\n--> 236                 tokenize(preprocess(self.decode(doc))), stop_words)\n        doc = <1x1000 sparse matrix of type '<class 'numpy.int... stored elements in Compressed Sparse Row format>\n    237 \n    238         else:\n    239             raise ValueError('%s is not a valid tokenization scheme/analyzer' %\n    240                              self.analyzer)\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/sklearn/feature_extraction/text.py in <lambda>(x=<1x1000 sparse matrix of type '<class 'numpy.int... stored elements in Compressed Sparse Row format>)\n    197         else:\n    198             raise ValueError('Invalid value for \"strip_accents\": %s' %\n    199                              self.strip_accents)\n    200 \n    201         if self.lowercase:\n--> 202             return lambda x: strip_accents(x.lower())\n        x = <1x1000 sparse matrix of type '<class 'numpy.int... stored elements in Compressed Sparse Row format>\n        x.lower = undefined\n    203         else:\n    204             return strip_accents\n    205 \n    206     def build_tokenizer(self):\n\n...........................................................................\n/Users/matar/anaconda/envs/py3k/lib/python3.3/site-packages/scipy/sparse/base.py in __getattr__(self=<1x1000 sparse matrix of type '<class 'numpy.int... stored elements in Compressed Sparse Row format>, attr='lower')\n    503         elif attr == 'imag':\n    504             return self._imag()\n    505         elif attr == 'size':\n    506             return self.getnnz()\n    507         else:\n--> 508             raise AttributeError(attr + \" not found\")\n        attr = 'lower'\n    509 \n    510     def transpose(self):\n    511         return self.tocsr().transpose()\n    512 \n\nAttributeError: lower not found\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "#grid search params\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)], #either uni or bigrams\n",
    "               'tfidf__use_idf': (True, False), #use or don't use idf\n",
    "               'clf__alpha': (1e-2, 1e-3)} #with different penalty params for linear svm\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1) #fit grid search instance\n",
    "\n",
    "gs_clf = gs_clf.fit(counts[tr], targets[tr]) #fit on one cv fold\n",
    "\n",
    "best_parameters, score, _ = max(gs_clf.grid_scores_, key=lambda x: x[1]) #find best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9321719792438844"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(text_clf.predict(df['Text']) == df['Category']) #cheating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear SVC\n",
      "\tmean score: 0.515925925925926\n",
      "\n",
      "Naive Bayes\n",
      "\t mean score: 0.45962962962962955\n",
      "\n",
      "Linear SVM\n",
      "\t mean score: 0.5714814814814815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n#decision tree\\nmod = DecisionTreeClassifier(criterion = 'entropy')\\ncv = StratifiedShuffleSplit(targets, n_iter = 10, test_size = 0.1)\\n\\nscores = []\\nfor tr, tt in cv:\\n    mod.fit(counts[tr], targets[tr])\\n    scores.append(mod.score(counts[tt],targets[tt]))\\nprint('\\nDecision Tree\\n\\t mean score: {0}'.format(np.mean(scores)))\\n\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## vectorize data\n",
    "#targets\n",
    "vec_tar = LabelEncoder()\n",
    "targets = vec_tar.fit_transform(df['Category'])\n",
    "#counts\n",
    "#vec = CountVectorizer(stop_words=ENGLISH_STOP_WORDS)\n",
    "vec = CountVectorizer(analyzer = 'char_wb', ngram_range= (5,5), stop_words = ENGLISH_STOP_WORDS) #use characters and bigrams more robust against mispellings (ngrams within word boundaries)\n",
    "counts = vec.fit_transform(df['Text']) \n",
    "\n",
    "## cv folds\n",
    "cv = StratifiedShuffleSplit(targets, n_iter=10, test_size=.1)\n",
    "\n",
    "## calculate tf-idf\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "counts_tfidf = tfidf_transformer.fit_transform(counts)\n",
    "\n",
    "## compare models\n",
    "#linear SVC\n",
    "mod = LinearSVC(C=.1)\n",
    "scores = []\n",
    "for tr, tt in cv:\n",
    "    mod.fit(counts_tfidf[tr], targets[tr])\n",
    "    scores.append(mod.score(counts_tfidf[tt],targets[tt]))\n",
    "print('\\nLinear SVC\\n\\tmean score: {0}'.format(np.mean(scores)))\n",
    "\n",
    "#naive bayes\n",
    "mod = MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
    "scores = []\n",
    "for tr, tt in cv:\n",
    "    mod.fit(counts_tfidf[tr], targets[tr])\n",
    "    scores.append(mod.score(counts_tfidf[tt],targets[tt]))\n",
    "print('\\nNaive Bayes\\n\\t mean score: {0}'.format(np.mean(scores)))\n",
    "\n",
    "#svm\n",
    "mod = SGDClassifier(loss = 'hinge',penalty = 'L2',alpha = 1e-3)\n",
    "scores = []\n",
    "for tr, tt in cv:\n",
    "    mod.fit(counts_tfidf[tr], targets[tr])\n",
    "    scores.append(mod.score(counts_tfidf[tt],targets[tt]))\n",
    "print('\\nLinear SVM\\n\\t mean score: {0}'.format(np.mean(scores)))\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "#decision tree\n",
    "mod = DecisionTreeClassifier(criterion = 'entropy')\n",
    "cv = StratifiedShuffleSplit(targets, n_iter = 10, test_size = 0.1)\n",
    "\n",
    "scores = []\n",
    "for tr, tt in cv:\n",
    "    mod.fit(counts[tr], targets[tr])\n",
    "    scores.append(mod.score(counts[tt],targets[tt]))\n",
    "print('\\nDecision Tree\\n\\t mean score: {0}'.format(np.mean(scores)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10c6a9550>,\n",
       " <matplotlib.lines.Line2D at 0x10c6a9910>,\n",
       " <matplotlib.lines.Line2D at 0x10c6a9b90>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAECCAYAAAD9z2x7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFihJREFUeJzt3X10VPWdx/HP5AGDSQhC8XBamgi0Rd1ssYl2WZXHrake\nwllrQwTTwNacCrH40AOcpohKckiNIKenFVzAY8XGukEELcWtrRYUD4pGOLAkCKxZiCIgCWjITAiZ\nZO7+ETM1kkzGzEPu3N/79U+dey/3fu83dz69c+f+5rosy7IEAHC8uIEuAAAQHQQ+ABiCwAcAQxD4\nAGAIAh8ADEHgA4AhEgLN9Hq9WrJkiU6cOKG2tjYVFxdr2rRp/vnbt2/XE088oYSEBP34xz/WzJkz\nI14wAKB/Agb+n//8Zw0bNkwrV65UU1OTbr31Vn/ge71eVVRUaPPmzUpKStLs2bM1bdo0DR8+PCqF\nAwC+moCXdG6++Wbde++9kiSfz6f4+Hj/vLq6OqWnpys1NVWJiYnKzs5WdXV1ZKsFAPRbwDP8Sy+9\nVJLkdrt133336Re/+IV/ntvtVmpqqv91cnKympubI1QmACBUAQNfkk6ePKkFCxaooKBA06dP909P\nTU2Vx+Pxv/Z4PEpLS+t1Pa2traqpqdGIESO6fVIAAPSuo6NDDQ0NyszMVFJSUkjrChj4jY2NuvPO\nO/Xwww9rwoQJ3eaNGTNG9fX1ampq0uDBg1VdXa2ioqJe11VTU6OCgoKQigUAU/3xj3/UtddeG9I6\nAgb+2rVr1dzcrDVr1mjNmjWSpPz8fJ0/f175+fkqKSlRUVGRfD6f8vLydPnll/e6rhEjRviLHjly\npH/6BwtHd86/rUxpNxSGtDMI3p8+rNX97/xJknR05pIBruZi7edO61jpv0iSvrXq6ABXE/ua3npW\nDZsflEQ/Y82pU6dUUFDgz9BQBAz8pUuXaunSpb3Onzp1qqZOnRrUhrou44wcOVKjRo3yTz+X1N45\nffgQDfvCdETW0Aun1T608zuaUTbsu/ezeLV8fmzYsb5Yc+nwNLnoZ0wLx6VwBl4BgCEIfAAwBIEP\nAIYg8AHAEAQ+ABiCwAcAQxD4AGAIAh8ADEHgA4AhCHwAMASBDwCGIPABwBAEPgAYgsAHAEMQ+ABg\nCAIfAAxB4AOAIQh8ADAEgQ8AhiDwAcAQBD4AGILABwBDEPgAYAgCHwAMQeADgCEIfAAwBIEPAIYg\n8AHAEAQ+ABiCwAcAQxD4AGAIAh8ADGGfwHe5BroCo9BtwDz2CXzLGugKjGL7bnM8hBn9hJ0CHwAQ\nUQQ+7IlLfGFGP0HgA4AxCHwAMASBDwCGIPABwBAEPgAYgsAHAEMQ+ABgCAIfAAxB4AOAIQh8ADAE\ngQ8AhiDwAcAQQQX+/v37VVhYeNH0DRs2KDc3V4WFhSosLNTRo0fDXiAAIDwS+lrgySef1NatW5Wc\nnHzRvNraWq1YsUJXX3116JXw64hRRbcB8/R5hp+RkaHVq1fL6uGBFLW1tVq7dq3uuOMOrV+/PiIF\nAgDCo8/Az8nJUXx8fI/zpk+frrKyMj3zzDPas2ePXn/99XDXBwAIk5C+tJ07d66GDh2qxMRETZ48\nWQcPHuz/ynikXVTRbcA8/Q785uZmzZgxQy0tLbIsS7t371ZmZmY4awMAhFGfX9p2cX3+peq2bdvU\n0tKi/Px8LVy4UHPmzNGgQYN0/fXXa9KkSRErFAAQmqACf9SoUaqqqpIk5ebm+qfn5uZ2ew0AsC8G\nXgGAIQh8ADAEgQ8AhiDwAcAQBD4AGILABwBDEPgAYAgCHwAMQeADgCEIfAAwhH0CnwegRBXdBsxj\nn8AHAEQUgQ8AhiDwAcAQ9gl8nngVVbbvNsdDmNFP2CnwAQARReDDnrhrK8zoJwh8ADAGgQ8AhiDw\nAcAQBD4AGILABwBDEPgAYAgCHwAMQeADgCEIfAAwBIEPAIawT+AzlD6q6DZgHvsEPgAgogh8ADAE\ngQ8AhiDwAcAQBD4AGMI+gc8j7aKKbgPmsU/gAwAiisAHAEMQ+ABgCAIfAAxB4AOAIQh8ADAEgQ8A\nhiDwAcAQBD4AGILABwBD2CfweQBKVNFtwDz2CXwAQEQR+ABgCAIfAAwRVODv379fhYWFF03fvn27\n8vLyNGvWLG3atCnsxQEAwiehrwWefPJJbd26VcnJyd2me71eVVRUaPPmzUpKStLs2bM1bdo0DR8+\nPGLFAgD6r88z/IyMDK1evVrWlx5QUldXp/T0dKWmpioxMVHZ2dmqrq6OWKEAgND0Gfg5OTmKj4+/\naLrb7VZqaqr/dXJyspqbm/tfSZifeHWs+azu2f2imtrO97ApSyXvvazdp+vDus0vO9HUqnu2HFCD\n+0KvyzzyP3/XK8cP9Trfe/a4Tlbeow732bDWFqjbb5yq00N7Xwlp/c/V7dW6Q2/3fwUOfALa3uOf\naeHWWnX4Au/b+WN7deq/FsnydQS97ueP7tOa93cFWCL2+vm/TQ1yPb1IWz+sDfrftH92Sicr71F7\n0ydBLf/4m0f1wv4T/S0x5vR5Sac3qamp8ng8/tcej0dpaWlhKSoc8nb8QXvOHNfg+EStuC6327zd\nDfV69MAOPXpgh6yfPhaxGn62ab/++/3Tampt1x/u+N5F8z3eC1qy5y+S1GsdH6+fo5b3d8hqb9PX\nf7ouYrV+0ZS//Kckac63rtW3hnytX+so2PmcJGnelf8atrpiXfZv3pQkTRk7XDP+aWSvyx19OFuS\nlHzVVKVeMz2odd/++rOSpJ9fdUOIVdrH97b+RpL0739/Ouj36cnKn6v5vS3qOHdao36+sc/l732p\nRpJkrfp6/wuNIf2+S2fMmDGqr69XU1OT2traVF1drWuuuSactYXk5PlzkqRPezjDb+1oj0oNpz8/\nsz/T0tbjfF8QZ10dn5+pdHjCe4YfDO9XOMMMOwcPxGtpC66vVltLGLcae/30tPf8vgmk/dzpzv91\nN4a7HEcI+gzf9fkbcNu2bWppaVF+fr5KSkpUVFQkn8+nvLw8XX755RErFAAQmqACf9SoUaqqqpIk\n5eb+4/LI1KlTNXXq1MhUBgAIKwZeAYAhCHwAMASBDwCGIPABwBCOD/wvjxAGAFPZJ/AdfN+1HdFt\nwDz2CfwIcfF/JAAgyYDABwB0IvABwBAEPgAYgsAHAEMQ+ABgCAIfAAzh+MBn4BUAdLJP4BPMUUW3\nAfPYJ/AjhIFXANDJ8YEPAOhE4AOAIQh8ADAEgQ8AhiDwAcAQjg987sMHgE6ODXwXj/gIGT0EnMU+\ngR/m++WtAEOLonXW37WZ3jYXTBn+/QhzzcF0O1AP0X/BdpVPp/3Q15vOcPYJfABARDk+8HsaaRut\n0bddm+ltc8GU4b+swohhxwj2L8ko8X7o601nOMcHPgCgE4EPAIYg8AHAEAQ+ABjC8YHPrW0A0Mmx\ngc+godDRQ8BZ7BP4nIlHle27zfEQZvQTdgr8MGOUaOjoIeAsjg38LgxeiVH83cKMfsKAwAcAdCLw\nAcAQBD4AGMLxgc99+AB6YmI2OD7wAQCd7BP4Yb4rg0FDgQXTHXoIOIt9Ah8AosjAKzrODXwGDYWO\nHgLO4tjA78LAKwDo5PjAB4CemPj5lcAHAEMQ+ABgCMcHvomDKwD0zcRsSAg00+fzadmyZTpy5IgS\nExNVXl6u9PR0//wNGzbohRde0GWXXSZJKisr0+jRoyNbcZC4hzx09BBwloCB/9prr8nr9aqqqkr7\n9+9XRUWFnnjiCf/82tparVixQldffXXECwUAhCZg4O/du1cTJ06UJI0fP141NTXd5tfW1mrt2rVq\nbGzUlClTdNddd0WuUgAII/Mu6PRxDd/tdislJcX/Oj4+Xj6fz/96+vTpKisr0zPPPKM9e/bo9ddf\n738lYb6eZqdBQ2HZtbD3J5hlBrCHDr6+Guyehfcas3P72SMHHz+hCBj4KSkp8ng8/tc+n09xcf/4\nJ3PnztXQoUOVmJioyZMn6+DBg5GrFAAQkoCBn5WVpZ07d0qS9u3bp3HjxvnnNTc3a8aMGWppaZFl\nWdq9e7cyMzMjW20/2GGkbVhKsMF+RJWD9zfYPQvvsevcfvYoiN6Z+CEg4DX8m266Sbt27dKsWbMk\nSY888oi2bdumlpYW5efna+HChZozZ44GDRqk66+/XpMmTYpK0QCAry5g4LtcLpWWlnab9sXbLnNz\nc5WbmxuZysLExHttAaAnjh94BQA9sdONHdFin8DnAShRxQNQAPPYJ/ABABFF4AMwkolf7zk28ANd\nn4vWF7ldm+ltc8GU4d+PATg6TbzGGQ0DM/DKEH296Qzn2MAHAHTn+MDvafBKtAZjdW0mlM35vzh1\n8EAk0wzMwCtDfIU3nYmfARwf+ACATo4PfK6DAkAnxwY+95CHjh7CyUw8GXRs4AMAuiPwAcAQBD4A\nIxl4RcdGgW9i9weQ7bvN8RBm9BN2Cvwwi4VRonav0e71AfhqHBv4XRi8EqP4u4UZ/fwyE09nHB/4\nJt56BQA9cXzgAwA62SfweQBKVPEAFJjOxA//9gl8AEBEEfgAjGTiXWgEPgAYgsAHAEM4NvBj4eOa\n3b80ioUeAv1l9/dfJDg28Lsw8AoAOjk+8Bl4BQCdHB/4ANATE08FHRv4DBoKHT0EnMWxgQ8A6I7A\nB2AkE7/fI/ABwBAEPgAYwj6BH+aPV4EGDUXro1zXZnrbXDADm/zLhL0/wSwzgB95HfxxO9g9C+9x\n6tx+dtPXm+6Li0a4FDuyT+ADACLKyMCP1ujbrs2Esjn/rZGmjRh28P4Gu2fhPU6d289uwvGmczD7\nBD4PQIkqHoAC0zn4qmGv7BP4AICIIvABwBAEPgAjMfAKAOBYBD4AGMKxgR8bA6+CWEeEBl4Fgyde\nRcbADLwyBAOvAnJs4AMAujMy8Bl4hYE0MAOvDMHAq4AcG/gMGgodPYSTmXjFzLGBDwDojsAHAEME\nDHyfz6eHHnpIs2bNUmFhoT788MNu87dv3668vDzNmjVLmzZtimihABBOBl7RCRz4r732mrxer6qq\nqrRo0SJVVFT453m9XlVUVOjpp59WZWWlNm7cqDNnzkS8YABA/wQM/L1792rixImSpPHjx6umpsY/\nr66uTunp6UpNTVViYqKys7NVXV0d2WoBAP2WEGim2+1WSkqK/3V8fLx8Pp/i4uLkdruVmprqn5ec\nnKzm5uY+N3j05Edqsdoumn76zCk1fvR/X6X2gOJbPlOat1WepgYd+dJ6TzR+pDTveUm6aF44+c5/\nojRXi9rc7T1up6ntfJ91tJ/v7Km7+dOw1nq64eNet901vf7kMcU1u/u1/pD7e+4T/39G8m8UTWmu\ns5KkT858qCMfXehz+ZMNJ3QqyH3vq9++M6f8/x0r/ezaJyn4mts95yRJ591Nff6bsy0X/H+T+lPH\nlTFyVD8rjR0uK8BwvoqKCo0fP1633HKLJGny5Ml64403JEmHDx/WqlWrtH79eknSI488ouzsbOXk\n5PS4rvr6euXk5Kj8qg/1tUvaw70fABCSHf9cqJ/9R9lAl3GRU6dOqaCgQH/729+UkZER0roCnuFn\nZWVpx44duuWWW7Rv3z6NGzfOP2/MmDGqr69XU1OTBg8erOrqahUVFfW6roaGBknSA++nh1QwAETE\nvl2qqvy3ga6iVw0NDSEHfsAzfMuytGzZMh0+fFhS51l8bW2tWlpalJ+frx07dmjNmjXy+XzKy8vT\nHXfc0euGWltbVVNToxEjRig+Pj6kogHAFB0dHWpoaFBmZqaSkpJCWlfAwAcAOAcDrwDAEAQ+ABiC\nwAcAQxD4AGCIgLdlhovP59OyZct05MgRJSYmqry8XOnp9ro9c//+/XrsscdUWVmp+vp6lZSUKC4u\nTt/+9rf18MMPy+Vy6fnnn9fGjRuVkJCg4uJiTZkyRa2trVq8eLHOnj2r5ORkVVRUaNiwYVGr2+v1\nasmSJTpx4oTa2tpUXFyssWPHxkz9HR0dWrp0qY4dOyaXy6XS0lINGjQoZurvcubMGd12223asGGD\n4uLiYqr+H/3oR/4Blt/85jc1b968mKp/3bp12rFjh7xer37yk58oKysrJup/8cUXtWXLFknShQsX\ndOjQIT333HMqLy+PXO1WFPz1r3+1SkpKLMuyrH379lnFxcXR2GzQ1q9fb+Xm5lq33367ZVmWNW/e\nPOvdd9+1LMuyHnroIevVV1+1Tp8+beXm5lptbW1Wc3OzlZuba124cMH6/e9/bz3++OOWZVnWyy+/\nbC1fvjyqtW/evNn69a9/bVmWZX322WfW5MmTrfnz58dM/a+++qq1ZMkSy7Is65133rHmz58fU/Vb\nlmW1tbVZd999t/XDH/7Qqquri6njp7W11br11lu7TYul+nfv3m3NmzfPsizL8ng81m9/+9uYO34s\ny7JKS0ut559/PuK1R+WSTqDf5LGDjIwMrV692v8M0YMHD+q6666TJE2aNElvvfWWDhw4oKysLCUm\nJiolJUUZGRk6fPiw9u7dq0mTJkmSJk6cqLfffjuqtd9888269957JXV+kkpISIip+n/wgx+orKxz\ndOPHH3+stLQ01dbWxkz9krRixQrNnj1bI0aMkBRbx8+hQ4d0/vx5FRUVae7cudq3b19M1b9r1y6N\nGzdOd999t+bPn69p06bF3PFz4MABffDBB5o5c2bEa49K4Pf2mzx2kZOT020wmPWFoQldvxHU028H\nud1uud1uJScnd1s2mi699FJ/Lffdd5/uv//+br21e/1S5/FQUlKi8vJyzZgxI6b6v2XLFg0bNkw3\n3nijpM5jJ5bqHzx4sIqKivTUU0+ptLRUixYt6jbf7vWfPXtWNTU1+t3vfqfS0lItXLgwpvovdV6S\nWrBggaTIZ09UruGnpKTI4/H4X3f9AJtdfbE2t9utIUOGXLQPHo9Hqamp3aZ7PB4NGTIk6vWePHlS\nCxYsUEFBgXJzc7Vy5cqYql/q/N2mxsZGzZw5U21t//hxPbvXv2XLFrlcLr311ls6dOiQSkpK9Omn\nn8ZM/VdccYV/uP4VV1yhoUOH6v3334+Z+i+77DKNHTtWCQkJGj16tC655BKdPn06Zuo/d+6cjh07\npu9///uSIp89UUndrKws7dy5U5Iu+k0eO7rqqqv07rvvSpJ27typa6+9Vt/97nf13nvvqa2tTc3N\nzaqrq9N3vvOdbvvWtWw0NTY26s4779TixYt12223xVz9L730ktatWydJSkpKUlxcnDIzM2Om/mef\nfVaVlZWqrKzUlVdeqUcffVQ33nhjzNS/ZcsW/3MuPvnkE3k8Ht1www0xU392drbefPNNf/2tra2a\nMGFCzNRfXV2tCRMm+F9H+r0blZ9WsHr4TZ7Ro0dHerNfyfHjx7Vo0SJVVVXp2LFjevDBB+X1ejV2\n7FgtX75cLpdLmzZt0saNG+Xz+VRcXKybbrpJra2t+uUvf6mGhgYNGjRIq1at0vDhw6NW9/Lly/XK\nK6906+cDDzyg8vLymKi/tbVVJSUlamxsVHt7u+666y6NGTMmZvr/RYWFhSorK5PL5YqZ+tvb2/Wr\nX/1KJ06ckCQtXrxYQ4cOjZn6JWnlypV655135PP5tHDhQn3jG9+ImfqfeuopJSYmas6cOZIU8ezh\nt3QAwBD2vZAOAAgrAh8ADEHgA4AhCHwAMASBDwCGIPABwBAEPgAYgsAHAEP8P3FHYz5j4dLPAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c142410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#each color is a question, x axis is the words, y axis is the counts (like histogram)\n",
    "plt.plot(counts[:3,:].toarray().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_words = {}\n",
    "for itrg in np.unique(targets):\n",
    "    cat = vec_tar.classes_[itrg]\n",
    "    # Pull rows for the current category, sum all rows (each element is a word)\n",
    "    icounts = counts[targets == itrg, :].sum(0).squeeze() \n",
    "    \n",
    "    # Which word counts occured >5 times\n",
    "    mask_top_words = icounts > 5\n",
    "    \n",
    "    # Turns vectors back into actual words (inverse transform - magical!)\n",
    "    top_words[cat] = vec.inverse_transform(mask_top_words)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keep words that are unique to that category\n",
    "unique_words = {}\n",
    "for cat, words in zip(top_words.keys(), top_words.values()):\n",
    "    others = top_words.copy()\n",
    "    others.pop(cat)\n",
    "    unique_words[cat] = [wrd for wrd in top_words[cat]\n",
    "                         if wrd not in np.hstack(others.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.511111111111\n",
      "0.566666666667\n",
      "0.537037037037\n",
      "0.503703703704\n",
      "0.503703703704\n",
      "0.537037037037\n",
      "0.525925925926\n",
      "0.511111111111\n",
      "0.544444444444\n",
      "0.522222222222\n",
      "Linear SVC mean score: 0.5262962962962963\n"
     ]
    }
   ],
   "source": [
    "#try SVC\n",
    "mod = LinearSVC(C=.1)\n",
    "cv = StratifiedShuffleSplit(targets, n_iter=10, test_size=.1)\n",
    "\n",
    "coefs, scores = [[] for i in range(2)]\n",
    "for tr, tt in cv:\n",
    "    mod.fit(counts[tr], targets[tr])\n",
    "    coefs.append(mod.coef_)\n",
    "    print(mod.score(counts[tt], targets[tt]))\n",
    "    scores.append(mod.score(counts[tt],targets[tt]))\n",
    "coefs = np.array(coefs).mean(0)\n",
    "\n",
    "print('Linear SVC mean score: {0}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.52962962963\n",
      "0.57037037037\n",
      "0.518518518519\n",
      "0.548148148148\n",
      "0.577777777778\n",
      "0.562962962963\n",
      "0.57037037037\n",
      "0.566666666667\n",
      "0.588888888889\n",
      "0.581481481481\n",
      "Naive Bayes mean score: 0.5438888888888889\n"
     ]
    }
   ],
   "source": [
    "#try Naive Bayes\n",
    "mod = MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
    "cv = StratifiedShuffleSplit(targets, n_iter = 10, test_size = 0.1)\n",
    "\n",
    "coefs = []\n",
    "for tr, tt in cv:\n",
    "    mod.fit(counts[tr], targets[tr])\n",
    "    coefs.append(mod.coef_)\n",
    "    print(mod.score(counts[tt], targets[tt]))\n",
    "    scores.append(mod.score(counts[tt],targets[tt]))\n",
    "coefs = np.array(coefs).mean(0)\n",
    "\n",
    "print('Naive Bayes mean score: {0}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: [array(['best', 'does', 'good', 'know', 'like', 'make', 'need', 'people',\n",
      "       'want', 'yahoo'], \n",
      "      dtype='<U13')]\n",
      "2: [array(['best', 'computer', 'does', 'know', 'use', 'want', 'web', 'windows',\n",
      "       'xa', 'yahoo'], \n",
      "      dtype='<U13')]\n",
      "3: [array(['best', 'did', 'does', 'favorite', 'know', 'like', 'movie', 'music',\n",
      "       'song', 'xa'], \n",
      "      dtype='<U13')]\n",
      "4: [array(['boyfriend', 'does', 'friend', 'girl', 'guy', 'know', 'like',\n",
      "       'love', 'really', 'want'], \n",
      "      dtype='<U13')]\n",
      "5: [array(['best', 'college', 'does', 'good', 'help', 'know', 'need', 'school',\n",
      "       'word', 'xa'], \n",
      "      dtype='<U13')]\n",
      "6: [array(['bad', 'best', 'does', 'feel', 'good', 'help', 'know', 'like',\n",
      "       'pain', 'way'], \n",
      "      dtype='<U13')]\n",
      "7: [array(['does', 'earth', 'gas', 'life', 'make', 'really', 'tell', 'theory',\n",
      "       'world', 'xa'], \n",
      "      dtype='<U13')]\n"
     ]
    }
   ],
   "source": [
    "#look only at highly weighted\n",
    "for cat, icoef in zip(vec_tar.classes_, coefs):\n",
    "    cut = np.percentile(icoef, 99)\n",
    "    important = icoef > cut\n",
    "    print('{0}: {1}'.format(cat, vec.inverse_transform(important)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
