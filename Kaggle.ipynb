{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "sns.set_palette('colorblind')\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    df = pd.read_csv('newtrain.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "\n",
    "    #tokenize text\n",
    "    pattern = r'''(?x)    # set flag to allow verbose regexps\n",
    "         ([A-Z]\\.)+        # abbreviations, e.g. U.S.A.\n",
    "       | \\w+([-']\\w+)*        # words with optional internal hyphens\n",
    "       | \\$?\\d+(\\.\\d+)?%?  # currency and percentages, e.g. $12.40, 82%\n",
    "       | \\.\\.\\.            # ellipsis\n",
    "       | [.,;\"?():-_`]+  # these are separate tokens\n",
    "     '''\n",
    "\n",
    "    tokenize = lambda text: nltk.regexp_tokenize(text, pattern)\n",
    "    df['Tokens'] = df['Text'].apply(tokenize)\n",
    "    \n",
    "    def pos_tag(text):\n",
    "        tuples = nltk.pos_tag(text)\n",
    "        tags = []\n",
    "        for t in tuples:\n",
    "            tags.append(t[1])\n",
    "        return tags\n",
    "    def get_nouns(text):\n",
    "        wnlemmatizer = nltk.WordNetLemmatizer()\n",
    "        tuples = nltk.pos_tag(text)\n",
    "        tags = []\n",
    "        for t in tuples:\n",
    "            if t[1][0] == 'N':\n",
    "                tags.append(wnlemmatizer.lemmatize(t[0]))\n",
    "        return tags\n",
    "    df['Nouns'] = df['Tokens'].apply(get_nouns)\n",
    "    df['POS'] = df['Tokens'].apply(pos_tag)\n",
    "    make_string = lambda a: ' '.join(i for i in a)\n",
    "    df['Nouns'] = df['Nouns'].apply(make_string)\n",
    "    df['POS'] = df['POS'].apply(make_string)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vectorize data\n",
    "#turns words into a list of vectors - vector length is the total number of words\n",
    "#Vector elements correspond to 1 word (1/0 if word is/not present in the current item)\n",
    "def get_labels_features(df, max_f):\n",
    "    vec = CountVectorizer(analyzer = 'char_wb', ngram_range= (5,5), stop_words = ENGLISH_STOP_WORDS)\n",
    "    vec_tar = LabelEncoder()\n",
    "    targets = vec_tar.fit_transform(df['Category'])\n",
    "    \n",
    "    counts = vec.fit_transform(df['Text'])\n",
    "    print(\"Counts shape: \" + str(counts.shape))\n",
    "    nouns = vec.fit_transform(df['Nouns'])\n",
    "    print(\"Nouns shape: \" + str(nouns.shape))\n",
    "    pos = vec.fit_transform(df['POS'])\n",
    "    print(\"POS shape: \" + str(pos.shape))\n",
    "    \n",
    "    \n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    tfidf = tfidf_transformer.fit_transform(counts)\n",
    "    \n",
    "    #To combine or not to combine\n",
    "    nouns_array = nouns.toarray()\n",
    "    pos_array = pos.toarray()\n",
    "    combined = np.hstack((nouns_array, pos_array))\n",
    "    return targets, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#evaluate using 10 fold cross-validation, inspect results\n",
    "def cross_validate(targets, features):\n",
    "    #SVC\n",
    "    mod = LinearSVC(C=.1)\n",
    "    cv = StratifiedShuffleSplit(targets, n_iter=10, test_size=.1)\n",
    "\n",
    "    scores = []\n",
    "    for tr, tt in cv:\n",
    "        mod.fit(features[tr], targets[tr])\n",
    "        scores.append(mod.score(features[tt], targets[tt]))\n",
    "\n",
    "    print('\\nLinear SVC\\n\\t mean score: {0}'.format(np.mean(scores)))\n",
    "    \n",
    "    #svm\n",
    "    mod = SGDClassifier(loss = 'hinge',penalty = 'L2',alpha = 1e-3)\n",
    "    scores = []\n",
    "    for tr, tt in cv:\n",
    "        mod.fit(features[tr], targets[tr])\n",
    "        scores.append(mod.score(features[tt],targets[tt]))\n",
    "    print('\\nLinear SVM\\n\\t mean score: {0}'.format(np.mean(scores)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #naive bayes\n",
    "    mod = MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
    "    scores = []\n",
    "    for tr, tt in cv:\n",
    "        mod.fit(features[tr], targets[tr])\n",
    "        scores.append(mod.score(features[tt],targets[tt]))\n",
    "    print('\\nNaive Bayes\\n\\t mean score: {0}'.format(np.mean(scores)))\n",
    "    \n",
    "    \n",
    "    logreg = LogisticRegression()\n",
    "    scores = []\n",
    "    for tr, tt in cv:\n",
    "        logreg.fit(features[tr], targets[tr])\n",
    "        scores.append(logreg.score(features[tt],targets[tt]))\n",
    "    print('\\nLogReg\\n\\t mean score: {0}'.format(np.mean(scores)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>why are yawns contagious? when people yawn</td>\n",
       "      <td>[why, are, yawns, contagious, ?, when, people,...</td>\n",
       "      <td>yawn people</td>\n",
       "      <td>WRB VBP NNS JJ . WRB NNS VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>what is trans fat? how to reduce that? i heard...</td>\n",
       "      <td>[what, is, trans, fat, ?, how, to, reduce, tha...</td>\n",
       "      <td>trans tras body food</td>\n",
       "      <td>WP VBZ NNS JJ . WRB TO VB IN . PRP VBP IN NNS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>roth ira vs 401k? what is the difference betwe...</td>\n",
       "      <td>[roth, ira, vs, 401k, ?, what, is, the, differ...</td>\n",
       "      <td>roth ira v difference roth ira prefer</td>\n",
       "      <td>NN NN NNS CD . WP VBZ DT NN IN NN NN CC CD . W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>how many planes fedex has? i heard that it is ...</td>\n",
       "      <td>[how, many, planes, fedex, has, ?, i, heard, t...</td>\n",
       "      <td>plane fedex airline world</td>\n",
       "      <td>WRB JJ NNS NN VBZ . PRP VBP IN PRP VBZ DT JJS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>what is the best photo slideshow creation appl...</td>\n",
       "      <td>[what, is, the, best, photo, slideshow, creati...</td>\n",
       "      <td>photo slideshow creation application photo sli...</td>\n",
       "      <td>WP VBZ DT JJS NN NN NN NN WP VBZ DT JJS NN NN ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                               Text  \\\n",
       "0         5         why are yawns contagious? when people yawn   \n",
       "1         6  what is trans fat? how to reduce that? i heard...   \n",
       "2         1  roth ira vs 401k? what is the difference betwe...   \n",
       "3         1  how many planes fedex has? i heard that it is ...   \n",
       "4         2  what is the best photo slideshow creation appl...   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [why, are, yawns, contagious, ?, when, people,...   \n",
       "1  [what, is, trans, fat, ?, how, to, reduce, tha...   \n",
       "2  [roth, ira, vs, 401k, ?, what, is, the, differ...   \n",
       "3  [how, many, planes, fedex, has, ?, i, heard, t...   \n",
       "4  [what, is, the, best, photo, slideshow, creati...   \n",
       "\n",
       "                                               Nouns  \\\n",
       "0                                        yawn people   \n",
       "1                               trans tras body food   \n",
       "2              roth ira v difference roth ira prefer   \n",
       "3                          plane fedex airline world   \n",
       "4  photo slideshow creation application photo sli...   \n",
       "\n",
       "                                                 POS  \n",
       "0                       WRB VBP NNS JJ . WRB NNS VBP  \n",
       "1  WP VBZ NNS JJ . WRB TO VB IN . PRP VBP IN NNS ...  \n",
       "2  NN NN NNS CD . WP VBZ DT NN IN NN NN CC CD . W...  \n",
       "3  WRB JJ NNS NN VBZ . PRP VBP IN PRP VBZ DT JJS ...  \n",
       "4  WP VBZ DT JJS NN NN NN NN WP VBZ DT JJS NN NN ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data()\n",
    "df = add_features(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts shape: (2698, 23364)\n",
      "Nouns shape: (2698, 11808)\n",
      "POS shape: (2698, 39)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'TfidfTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6e67d1817d19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_labels_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-b4a041d75864>\u001b[0m in \u001b[0;36mget_labels_features\u001b[0;34m(df, max_f)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtfidf_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'TfidfTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "result = get_labels_features(df, 1000)\n",
    "labels = result[0]\n",
    "x = result[1]\n",
    "cross_validate(labels, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#result = get_labels_features(df, 1000)\n",
    "#labels = result[0]\n",
    "#x = result[1]\n",
    "#cross_validate(labels, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#result = get_labels_features(df, 1000)\n",
    "#labels = result[0]\n",
    "#x = result[1]\n",
    "#cross_validate(labels, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
